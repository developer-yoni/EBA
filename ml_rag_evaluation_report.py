"""\
RAG(Knowledge Base)ì—ì„œ ì‹œê³„ì—´ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ Linear Regression(ë¹„ìœ¨/Ratio ë°©ì‹)ìœ¼ë¡œ í‰ê°€í•˜ê³ ,
ê²°ê³¼ë¥¼ ml_result.png, ml_result.txtë¡œ ì €ì¥í•©ë‹ˆë‹¤.

ìš”êµ¬ì‚¬í•­(ìš”ì•½):
- RAGì—ì„œ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì™€ test setìœ¼ë¡œ ì‚¬ìš©
- Linear Regression ê¸°ë°˜ (GS ì¶©ì „ê¸°/ì‹œì¥ ì „ì²´ ê°ê° íšŒê·€ í›„ ì ìœ ìœ¨=GS/ì‹œì¥*100)
- ì—¬ëŸ¬ í…ŒìŠ¤íŠ¸(ë¡¤ë§ ë°±í…ŒìŠ¤íŠ¸, ì‹œê³„ì—´ CV, ì˜¤ì°¨ ë¶„í¬)
- ë¹„ì „ê³µìë„ ì´í•´ ê°€ëŠ¥í•œ ì„¤ëª… + í•µì‹¬ ì§€í‘œëŠ” ìœ ì§€

ì‹¤í–‰:
- python ml_rag_evaluation_report.py

ì£¼ì˜:
- AWS Bedrock/Knowledge Base ì ‘ê·¼ì„ ìœ„í•´ ë„¤íŠ¸ì›Œí¬ ë° ìê²©ì¦ëª…ì´ í•„ìš”í•©ë‹ˆë‹¤.
- í™˜ê²½ë³€ìˆ˜ëŠ” config.pyì˜ Configë¥¼ ë”°ë¦…ë‹ˆë‹¤(.env ì‚¬ìš© ê°€ëŠ¥).
"""

from __future__ import annotations

import os
import json
import math
import re
from dataclasses import dataclass
from datetime import datetime
from typing import Any, Dict, Iterable, List, Optional, Tuple

import boto3
import numpy as np
import pandas as pd

# Matplotlibì´ ê¸°ë³¸ ìºì‹œ ê²½ë¡œ(~/.matplotlib)ì— ì“°ê¸° ì‹¤íŒ¨í•˜ëŠ” í™˜ê²½ì´ ìˆì–´,
# í”„ë¡œì íŠ¸ ë‚´ë¶€ì˜ ì“°ê¸° ê°€ëŠ¥í•œ ê²½ë¡œë¥¼ ê¸°ë³¸ìœ¼ë¡œ ì§€ì •í•©ë‹ˆë‹¤.
_MPLCONFIGDIR = os.path.join(os.path.dirname(__file__), ".mplconfig")
os.makedirs(_MPLCONFIGDIR, exist_ok=True)
os.environ.setdefault("MPLCONFIGDIR", _MPLCONFIGDIR)

import matplotlib.pyplot as plt

from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.model_selection import TimeSeriesSplit

from config import Config
from data_loader import ChargingDataLoader


# ê¸°ë³¸ ê²€ì¦ ë²”ìœ„ (ì‚¬ìš©ì ìš”êµ¬: RAGì˜ 2024-12 ~ 2025-11)
DEFAULT_TEST_START_MONTH = "2024-12"
DEFAULT_TEST_END_MONTH = "2025-11"


def _month_to_ym(month: str) -> Tuple[int, int]:
    m = _normalize_month_str(month)
    if not m:
        raise ValueError(f"Invalid month: {month}")
    y, mm = m.split("-")
    return int(y), int(mm)


def generate_month_range(start_month: str, end_month: str) -> List[str]:
    """YYYY-MM ë²”ìœ„(í¬í•¨)ë¥¼ ì›” ë‹¨ìœ„ë¡œ ìƒì„±."""
    sy, sm = _month_to_ym(start_month)
    ey, em = _month_to_ym(end_month)

    months: List[str] = []
    y, m = sy, sm
    while (y, m) <= (ey, em):
        months.append(f"{y:04d}-{m:02d}")
        m += 1
        if m == 13:
            y += 1
            m = 1
    return months


def _to_yymm(month: str) -> str:
    """YYYY-MM -> YYMM (ì˜ˆ: 2025-11 -> 2511)"""
    y, m = _month_to_ym(month)
    return f"{y % 100:02d}{m:02d}"


def build_timeseries_from_s3(months: List[str]) -> Tuple[pd.DataFrame, Dict[str, Any]]:
    """S3 ì—‘ì…€(í”„ë¡œì íŠ¸ í‘œì¤€ ë¡œë”)ë¡œ ì›”ë³„ ì‹œê³„ì—´ì„ êµ¬ì„±.

    - í”„ë¡œì íŠ¸ ë‚´ ê¸°ì¡´ ë¡œì§(`ChargingDataLoader.load_multiple`)ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©
    - ê²°ê³¼ DF ì»¬ëŸ¼ì€ RAGTimeSeriesExtractor ì¶œë ¥ê³¼ ë™ì¼ í˜•íƒœë¡œ ë§ì¶¤
    """
    meta: Dict[str, Any] = {
        "source": "s3_loader_fallback",
        "s3_bucket": Config.S3_BUCKET,
        "s3_prefix": Config.S3_PREFIX,
        "period_requested": {"start": months[0] if months else None, "end": months[-1] if months else None},
    }

    yymm_list = [_to_yymm(m) for m in months]
    loader = ChargingDataLoader()
    full_data = loader.load_multiple(months=yymm_list)
    if full_data is None or len(full_data) == 0:
        return pd.DataFrame(), meta

    records: List[MonthlyRecord] = []
    missing: List[str] = []
    for m in months:
        month_data = full_data[full_data["snapshot_month"] == m]
        if len(month_data) == 0:
            missing.append(m)
            continue

        market_total = int(month_data["ì´ì¶©ì „ê¸°"].sum()) if "ì´ì¶©ì „ê¸°" in month_data.columns else 0
        gs_rows = month_data[month_data["CPOëª…"] == "GSì°¨ì§€ë¹„"] if "CPOëª…" in month_data.columns else pd.DataFrame()
        if len(gs_rows) == 0:
            missing.append(m)
            continue

        gs_total = int(gs_rows.iloc[0].get("ì´ì¶©ì „ê¸°", 0))
        share_val = gs_rows.iloc[0].get("ì‹œì¥ì ìœ ìœ¨", 0)
        try:
            share = float(share_val) if pd.notna(share_val) else 0.0
        except Exception:
            share = 0.0
        if 0 < share < 1:
            share *= 100
        if share <= 0 and market_total > 0 and gs_total > 0:
            share = (gs_total / market_total) * 100

        if gs_total <= 0 or market_total <= 0:
            missing.append(m)
            continue

        records.append(
            MonthlyRecord(
                month=m,
                gs_total_chargers=gs_total,
                market_total_chargers=market_total,
                gs_market_share_pct=share,
            )
        )

    if not records:
        meta["missing_months"] = months
        return pd.DataFrame(), meta

    df = pd.DataFrame([r.__dict__ for r in records]).sort_values("month").reset_index(drop=True)
    meta["missing_months"] = missing
    meta["period"] = {"start": df["month"].iloc[0], "end": df["month"].iloc[-1], "n_months": int(len(df))}
    return df, meta


# -----------------------------
# RAG -> ì‹œê³„ì—´ ë°ì´í„° ì¶”ì¶œ
# -----------------------------

def _extract_json_object(text: str) -> Optional[Dict[str, Any]]:
    """LLM ì‘ë‹µì—ì„œ JSON ì˜¤ë¸Œì íŠ¸ 1ê°œë¥¼ ìµœëŒ€í•œ ì•ˆì „í•˜ê²Œ ì¶”ì¶œ."""
    if not text:
        return None

    # 1) ```json ... ``` ë¸”ë¡ ìš°ì„ 
    m = re.search(r"```json\s*([\s\S]*?)\s*```", text)
    if m:
        candidate = m.group(1).strip()
        try:
            return json.loads(candidate)
        except json.JSONDecodeError:
            pass

    # 2) ì²« { ... } ë¥¼ ë„“ê²Œ ì¡ì•„ ì‹œë„
    m2 = re.search(r"\{[\s\S]*\}", text)
    if m2:
        candidate = m2.group(0).strip()
        try:
            return json.loads(candidate)
        except json.JSONDecodeError:
            return None

    return None


def _normalize_month_str(s: str) -> Optional[str]:
    if not s:
        return None
    s = str(s).strip()

    # YYYY-MM
    m = re.match(r"^(\d{4})-(\d{2})$", s)
    if m:
        return f"{m.group(1)}-{m.group(2)}"

    # YYYY.MM
    m = re.match(r"^(\d{4})\.(\d{2})$", s)
    if m:
        return f"{m.group(1)}-{m.group(2)}"

    return None


@dataclass
class MonthlyRecord:
    month: str
    gs_total_chargers: int
    market_total_chargers: int
    gs_market_share_pct: float


class RAGTimeSeriesExtractor:
    """Knowledge Base(RAG)ì—ì„œ ì›”ë³„ ìˆ˜ì¹˜ë¥¼ 'êµ¬ì¡°í™”(JSON)'ë¡œ ì¶”ì¶œ."""

    def __init__(self):
        self.kb_client = boto3.client(
            "bedrock-agent-runtime",
            region_name=Config.AWS_REGION,
            aws_access_key_id=Config.AWS_ACCESS_KEY_ID,
            aws_secret_access_key=Config.AWS_SECRET_ACCESS_KEY,
        )
        self.bedrock_client = boto3.client(
            "bedrock-runtime",
            region_name=Config.AWS_REGION,
            aws_access_key_id=Config.AWS_ACCESS_KEY_ID,
            aws_secret_access_key=Config.AWS_SECRET_ACCESS_KEY,
        )

    def _retrieve(self, query: str, n_results: int = 20) -> str:
        resp = self.kb_client.retrieve(
            knowledgeBaseId=Config.KNOWLEDGE_BASE_ID,
            retrievalQuery={"text": query},
            retrievalConfiguration={
                "vectorSearchConfiguration": {"numberOfResults": int(n_results)}
            },
        )
        results = resp.get("retrievalResults", [])
        if not results:
            return ""

        parts = []
        for i, r in enumerate(results, 1):
            txt = (r.get("content", {}) or {}).get("text", "")
            score = r.get("score")
            score_str = f"{score:.3f}" if isinstance(score, (float, int)) else "N/A"
            parts.append(f"[ë¬¸ì„œ {i}] (ê´€ë ¨ë„: {score_str})\n{txt}")
        return "\n\n---\n\n".join(parts)

    def _invoke_json(self, prompt: str, context: str) -> Tuple[Optional[Dict[str, Any]], str]:
        """ì»¨í…ìŠ¤íŠ¸ + í”„ë¡¬í”„íŠ¸ë¡œ Bedrockì„ í˜¸ì¶œí•˜ê³  JSONì„ íŒŒì‹±."""
        # ì»¨í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ì»¤ì§€ë©´ ì‹¤íŒ¨/ë¹„ìš© ì¦ê°€ â†’ ìƒí•œì„ 
        context = context or ""
        if len(context) > 20000:
            context = context[:20000] + "\n\n[TRUNCATED]"

        structured_prompt = (
            "ë‹¹ì‹ ì€ ì œê³µëœ ì°¸ê³ ìë£Œ(ê²€ìƒ‰ ê²°ê³¼)ë§Œ ì‚¬ìš©í•´ ìˆ«ìë¥¼ ì¶”ì¶œí•˜ëŠ” ë°ì´í„° ì• ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤.\n"
            "ì¶”ì¸¡ ê¸ˆì§€, ê³„ì‚°ì€ í—ˆìš©(í•„ìš”ì‹œ)í•˜ì§€ë§Œ ê³„ì‚° ê·¼ê±°ê°€ ë˜ëŠ” ìˆ«ìëŠ” ë°˜ë“œì‹œ ì°¸ê³ ìë£Œì—ì„œ ì°¾ì„ ìˆ˜ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.\n\n"
            f"## ì°¸ê³ ìë£Œ\n{context}\n\n"
            f"## ì‘ì—…\n{prompt}\n"
        )

        payload = {
            "anthropic_version": Config.ANTHROPIC_VERSION,
            "max_tokens": 2048,
            "temperature": 0.0,
            "messages": [{"role": "user", "content": structured_prompt}],
        }

        resp = self.bedrock_client.invoke_model(
            modelId=Config.MODEL_ID,
            contentType="application/json",
            accept="application/json",
            body=json.dumps(payload),
        )
        body = json.loads(resp["body"].read())
        text = body["content"][0]["text"]
        obj = _extract_json_object(text)
        return obj, text

    def extract_month_list(self) -> List[str]:
        """KB ë‚´ì—ì„œ í™œìš© ê°€ëŠ¥í•œ ì›”(YYYY-MM) ëª©ë¡ì„ ìµœëŒ€í•œ ë½‘ì•„ëƒ„."""
        query = "ì¶©ì „ì¸í”„ë¼ í˜„í™© ë°ì´í„° snapshot_month(YYYY-MM) ëª©ë¡ ì „ì²´"
        context = self._retrieve(query, n_results=30)

        prompt = (
            "ì°¸ê³ ìë£Œì—ì„œ í™•ì¸ ê°€ëŠ¥í•œ snapshot_month(YYYY-MM)ë“¤ì„ ëª¨ë‘ ì°¾ì•„, ì¤‘ë³µ ì œê±° í›„ ì˜¤ë¦„ì°¨ìˆœìœ¼ë¡œ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”.\n"
            "ì¶œë ¥ í˜•ì‹ì€ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.\n\n"
            "```json\n"
            "{\n"
            '  "months": ["2024-12", "2025-01"]\n'
            "}\n"
            "```\n"
        )

        obj, raw = self._invoke_json(prompt, context)
        if not obj or "months" not in obj:
            return []

        months = []
        for m in obj.get("months", []):
            nm = _normalize_month_str(m)
            if nm:
                months.append(nm)

        months = sorted(set(months))
        return months

    def extract_month_record(self, month: str) -> Optional[MonthlyRecord]:
        """íŠ¹ì • ì›”ì˜ GS/ì‹œì¥ ìˆ˜ì¹˜ 1ê°œ ë ˆì½”ë“œ ì¶”ì¶œ."""
        month = _normalize_month_str(month) or month
        query = f"ì¶©ì „ì¸í”„ë¼ í˜„í™© {month} GSì°¨ì§€ë¹„ ì´ì¶©ì „ê¸° ì‹œì¥ì ìœ ìœ¨ ì „ì²´CPO ì´ì¶©ì „ê¸°"
        context = self._retrieve(query, n_results=25)
        if not context:
            return None

        prompt = (
            "ì•„ë˜ ì›”ì— ëŒ€í•´ GSì°¨ì§€ë¹„ì™€ ì‹œì¥ ì „ì²´ì˜ í•µì‹¬ ìˆ˜ì¹˜ë¥¼ JSONìœ¼ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”.\n"
            "- month: YYYY-MM\n"
            "- gs_total_chargers: ì •ìˆ˜\n"
            "- market_total_chargers: ì •ìˆ˜\n"
            "- gs_market_share_pct: í¼ì„¼íŠ¸(ì˜ˆ: 16.25)\n\n"
            "ê°€ëŠ¥í•˜ë©´ 'ì‹œì¥ ì „ì²´ ì´ì¶©ì „ê¸°'ëŠ” ì—‘ì…€ ìš”ì•½(ì „ì²´CPO ì´ì¶©ì „ê¸°) ê°’ì„ ì‚¬ìš©í•˜ì„¸ìš”.\n"
            "gs_market_share_pctê°€ ì°¸ê³ ìë£Œì— ì—†ìœ¼ë©´ (gs_total_chargers/market_total_chargers*100)ìœ¼ë¡œ ê³„ì‚°í•´ë„ ë©ë‹ˆë‹¤.\n"
            "ë‹¨, ê³„ì‚°ì— ì“°ì¸ ë‘ ê°’ì€ ëª¨ë‘ ì°¸ê³ ìë£Œì—ì„œ ì°¾ì„ ìˆ˜ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.\n\n"
            f"ëŒ€ìƒ ì›”: {month}\n\n"
            "```json\n"
            "{\n"
            '  "month": "YYYY-MM",\n'
            "  \"gs_total_chargers\": 0,\n"
            "  \"market_total_chargers\": 0,\n"
            "  \"gs_market_share_pct\": 0.0\n"
            "}\n"
            "```\n"
        )

        obj, raw = self._invoke_json(prompt, context)
        if not obj:
            return None

        # ì›”ì€ 'ìš”ì²­í•œ month'ë¥¼ ìš°ì„  ì‹ ë¢°í•©ë‹ˆë‹¤.
        # (LLMì´ ì°¸ê³ ìë£Œì—ì„œ ë‹¤ë¥¸ ì›”ì„ í˜¼ë™í•´ ì ëŠ” ê²½ìš°ë¥¼ ë°©ì§€)
        target_month = _normalize_month_str(month)
        m = target_month or _normalize_month_str(obj.get("month"))
        if not m:
            return None

        def _to_int(v: Any) -> int:
            try:
                if v is None:
                    return 0
                if isinstance(v, str):
                    v = v.replace(",", "").strip()
                return int(float(v))
            except Exception:
                return 0

        def _to_float(v: Any) -> float:
            try:
                if v is None:
                    return 0.0
                if isinstance(v, str):
                    v = v.replace("%", "").replace(",", "").strip()
                return float(v)
            except Exception:
                return 0.0

        gs_total = _to_int(obj.get("gs_total_chargers"))
        market_total = _to_int(obj.get("market_total_chargers"))
        share = _to_float(obj.get("gs_market_share_pct"))

        # ì¼ë¶€ ë°ì´í„°ëŠ” 0~1 ë¹„ìœ¨ë¡œ ë“¤ì–´ì˜¤ëŠ” ê²½ìš°ê°€ ìˆì–´ ë³´ì •
        if 0 < share < 1:
            share *= 100

        if gs_total <= 0 or market_total <= 0:
            return None

        # ì ìœ ìœ¨ì´ 0ì´ë©´ ê³„ì‚°(ê°€ëŠ¥í•œ ê²½ìš°)
        if share <= 0 and market_total > 0:
            share = (gs_total / market_total) * 100

        return MonthlyRecord(
            month=m,
            gs_total_chargers=int(gs_total),
            market_total_chargers=int(market_total),
            gs_market_share_pct=float(share),
        )

    def build_timeseries(self, months: Optional[List[str]] = None) -> Tuple[pd.DataFrame, Dict[str, Any]]:
        """RAGì—ì„œ ì›”ë³„ ì‹œê³„ì—´ì„ ë§Œë“¤ê³  DFë¡œ ë°˜í™˜.

        - monthsë¥¼ ì£¼ë©´ í•´ë‹¹ ì›”ë“¤ë§Œ ì¶”ì¶œ
        - monthsê°€ ì—†ìœ¼ë©´ KBì—ì„œ ì›” ëª©ë¡ì„ ì¶”ì¶œí•˜ë˜, ê¸°ë³¸ì ìœ¼ë¡œëŠ” DEFAULT_TEST_* ë²”ìœ„ë¥¼ ìš°ì„  ì‚¬ìš©
        """
        meta: Dict[str, Any] = {
            "source": "rag_kb",
            "knowledge_base_id": Config.KNOWLEDGE_BASE_ID,
            "model_id": Config.MODEL_ID,
            "retrieval": {"month_list_results": None, "per_month_results": []},
        }

        requested_months = generate_month_range(DEFAULT_TEST_START_MONTH, DEFAULT_TEST_END_MONTH)

        if months is None:
            inferred = self.extract_month_list()
            meta["retrieval"]["month_list_results"] = {"n_months": len(inferred)}

            # ì‚¬ìš©ì ìš”êµ¬ ë²”ìœ„ë¥¼ ìš°ì„  ì‚¬ìš© (KB ì›”ëª©ë¡ì´ ë¶€ì •í™•/ëˆ„ë½ë  ë•Œ ì•ˆì •ì ìœ¼ë¡œ ê³ ì •)
            months = requested_months
            meta["retrieval"]["month_list_results"]["forced_default_range"] = True
        else:
            meta["retrieval"]["month_list_results"] = {"provided_months": len(months)}

        # í˜¹ì‹œë¼ë„ monthsê°€ ë¹„ë©´ ê¸°ë³¸ ë²”ìœ„ë¡œ ê°•ì œ
        if not months:
            months = requested_months
            meta["retrieval"]["month_list_results"] = {"forced_default_range": True, "n_months": len(months)}

        records: List[MonthlyRecord] = []
        for m in months:
            rec = self.extract_month_record(m)
            meta["retrieval"]["per_month_results"].append(
                {"month": m, "success": bool(rec)}
            )
            if rec:
                records.append(rec)

        if not records:
            return pd.DataFrame(), meta

        df = pd.DataFrame([r.__dict__ for r in records])
        df = df.drop_duplicates(subset=["month"]).sort_values("month").reset_index(drop=True)

        # ëˆ„ë½ ì›” ê¸°ë¡ (ìš”ì²­ ë²”ìœ„ ê¸°ì¤€)
        expected = [_normalize_month_str(m) for m in months]
        expected = [m for m in expected if m]
        got = set(df["month"].tolist())
        meta["missing_months"] = [m for m in expected if m not in got]

        meta["period"] = {
            "start": df["month"].iloc[0],
            "end": df["month"].iloc[-1],
            "n_months": int(len(df)),
        }
        return df, meta


# -----------------------------
# Linear Regression í‰ê°€
# -----------------------------


def _safe_mape_pct(y_true: np.ndarray, y_pred: np.ndarray) -> float:
    """MAPE(%) - 0ìœ¼ë¡œ ë‚˜ëˆ” ë°©ì§€."""
    y_true = np.asarray(y_true, dtype=float)
    y_pred = np.asarray(y_pred, dtype=float)
    denom = np.where(np.abs(y_true) < 1e-9, np.nan, np.abs(y_true))
    ape = np.abs((y_true - y_pred) / denom) * 100
    ape = ape[~np.isnan(ape)]
    if len(ape) == 0:
        return float("nan")
    return float(np.mean(ape))


@dataclass
class BacktestPoint:
    base_month: str
    target_month: str
    horizon: int
    predicted_share: float
    actual_share: float
    error_pp: float


class LinearRegressionRatioEvaluator:
    """GS/ì‹œì¥ ì´ëŸ‰ ê°ê° Linear Regression í›„ ë¹„ìœ¨ë¡œ ì ìœ ìœ¨ ì˜ˆì¸¡."""

    def __init__(self, df: pd.DataFrame):
        self.df = df.copy()
        self.df = self.df.sort_values("month").reset_index(drop=True)

        # ê¸°ë³¸ ê²€ì¦
        required = {"month", "gs_total_chargers", "market_total_chargers", "gs_market_share_pct"}
        missing = required - set(self.df.columns)
        if missing:
            raise ValueError(f"í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {sorted(missing)}")

        # float/int ë³€í™˜
        self.df["gs_total_chargers"] = pd.to_numeric(self.df["gs_total_chargers"], errors="coerce")
        self.df["market_total_chargers"] = pd.to_numeric(self.df["market_total_chargers"], errors="coerce")
        self.df["gs_market_share_pct"] = pd.to_numeric(self.df["gs_market_share_pct"], errors="coerce")
        self.df = self.df.dropna().reset_index(drop=True)

    def rolling_backtest(self, horizons: List[int] = [1, 2, 3, 4, 5, 6, 7, 8]) -> Dict[str, Any]:
        months = self.df["month"].tolist()
        gs = self.df["gs_total_chargers"].to_numpy(dtype=float)
        market = self.df["market_total_chargers"].to_numpy(dtype=float)
        share = self.df["gs_market_share_pct"].to_numpy(dtype=float)

        points: List[BacktestPoint] = []

        for h in horizons:
            # base index i: iê¹Œì§€ í•™ìŠµ, i+hê°€ íƒ€ê²Ÿ(ë¯¸ë˜)
            for i in range(2, len(months) - h):  # ìµœì†Œ 3ê°œì›”(ì¸ë±ìŠ¤ 0..2) í•™ìŠµ
                X_train = np.arange(i + 1).reshape(-1, 1)
                y_gs = gs[: i + 1]
                y_mkt = market[: i + 1]

                lr_gs = LinearRegression().fit(X_train, y_gs)
                lr_mkt = LinearRegression().fit(X_train, y_mkt)

                X_pred = np.array([[i + h]])
                pred_gs = float(lr_gs.predict(X_pred)[0])
                pred_mkt = float(lr_mkt.predict(X_pred)[0])
                pred_share = (pred_gs / pred_mkt) * 100 if pred_mkt > 0 else float("nan")

                actual_share = float(share[i + h])
                err = pred_share - actual_share

                points.append(
                    BacktestPoint(
                        base_month=months[i],
                        target_month=months[i + h],
                        horizon=h,
                        predicted_share=pred_share,
                        actual_share=actual_share,
                        error_pp=err,
                    )
                )

        # ìš”ì•½
        rows = []
        for p in points:
            rows.append(
                {
                    "base_month": p.base_month,
                    "target_month": p.target_month,
                    "horizon": p.horizon,
                    "predicted_share": p.predicted_share,
                    "actual_share": p.actual_share,
                    "error_pp": p.error_pp,
                    "abs_error_pp": abs(p.error_pp),
                }
            )
        bt_df = pd.DataFrame(rows)

        summary_by_h = {}
        for h in horizons:
            sub = bt_df[bt_df["horizon"] == h]
            if len(sub) == 0:
                continue

            y_true = sub["actual_share"].to_numpy(float)
            y_pred = sub["predicted_share"].to_numpy(float)
            mae = float(mean_absolute_error(y_true, y_pred))
            rmse = float(math.sqrt(mean_squared_error(y_true, y_pred)))
            mape = _safe_mape_pct(y_true, y_pred)
            reliability = float(max(0.0, 100.0 - mape)) if not math.isnan(mape) else float("nan")
            worst = float(sub["abs_error_pp"].max())

            summary_by_h[int(h)] = {
                "n_tests": int(len(sub)),
                "mae_pp": round(mae, 4),
                "rmse_pp": round(rmse, 4),
                "mape_pct": round(mape, 2) if not math.isnan(mape) else None,
                "reliability_pct": round(reliability, 2) if not math.isnan(reliability) else None,
                "worst_abs_error_pp": round(worst, 4),
            }

        overall = {}
        if len(bt_df) > 0:
            y_true = bt_df["actual_share"].to_numpy(float)
            y_pred = bt_df["predicted_share"].to_numpy(float)
            overall = {
                "n_tests": int(len(bt_df)),
                "mae_pp": round(float(mean_absolute_error(y_true, y_pred)), 4),
                "rmse_pp": round(float(math.sqrt(mean_squared_error(y_true, y_pred))), 4),
                "mape_pct": round(_safe_mape_pct(y_true, y_pred), 2),
            }
            overall["reliability_pct"] = round(max(0.0, 100.0 - overall["mape_pct"]), 2)

        return {
            "backtest_points": bt_df,
            "summary_by_horizon": summary_by_h,
            "overall": overall,
        }

    def timeseries_cv(self, n_splits: int = 5) -> Dict[str, Any]:
        n = len(self.df)
        n_splits = min(int(n_splits), max(2, n - 2))

        X = np.arange(n).reshape(-1, 1)
        gs = self.df["gs_total_chargers"].to_numpy(float)
        market = self.df["market_total_chargers"].to_numpy(float)
        share = self.df["gs_market_share_pct"].to_numpy(float)

        tscv = TimeSeriesSplit(n_splits=n_splits)

        share_true_all: List[float] = []
        share_pred_all: List[float] = []

        for tr, va in tscv.split(X):
            lr_gs = LinearRegression().fit(X[tr], gs[tr])
            lr_mkt = LinearRegression().fit(X[tr], market[tr])

            pred_gs = lr_gs.predict(X[va])
            pred_mkt = lr_mkt.predict(X[va])
            pred_share = (pred_gs / pred_mkt) * 100

            share_true_all.extend(share[va].tolist())
            share_pred_all.extend(pred_share.tolist())

        y_true = np.array(share_true_all, dtype=float)
        y_pred = np.array(share_pred_all, dtype=float)

        mae = float(mean_absolute_error(y_true, y_pred))
        rmse = float(math.sqrt(mean_squared_error(y_true, y_pred)))
        mape = _safe_mape_pct(y_true, y_pred)
        reliability = float(max(0.0, 100.0 - mape)) if not math.isnan(mape) else float("nan")

        return {
            "n_splits": int(n_splits),
            "n_points": int(len(y_true)),
            "mae_pp": round(mae, 4),
            "rmse_pp": round(rmse, 4),
            "mape_pct": round(mape, 2) if not math.isnan(mape) else None,
            "reliability_pct": round(reliability, 2) if not math.isnan(reliability) else None,
        }


# -----------------------------
# ë¦¬í¬íŠ¸/ì‹œê°í™” ìƒì„±
# -----------------------------


def _set_korean_font():
    try:
        plt.rcParams["font.family"] = "AppleGothic"  # macOS
    except Exception:
        try:
            plt.rcParams["font.family"] = "Malgun Gothic"  # Windows
        except Exception:
            pass
    plt.rcParams["axes.unicode_minus"] = False


def build_ml_result_png(
    df: pd.DataFrame,
    backtest_points: pd.DataFrame,
    summary_by_horizon: Dict[int, Any],
    output_path: str = "ml_result.png",
):
    _set_korean_font()

    df = df.sort_values("month").reset_index(drop=True)

    months = df["month"].tolist()
    actual_share = df["gs_market_share_pct"].to_numpy(float)

    # 1ê°œì›” ì•(1M) ì˜ˆì¸¡ì€ ì›”ë³„ ë¹„êµê°€ ê°€ì¥ ì§ê´€ì ì´ë¯€ë¡œ, ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì¤‘ 1Më§Œ ì¶”ë ¤ ë¼ì¸ìœ¼ë¡œ í‘œì‹œ
    pred_1m_df = None
    if len(backtest_points) > 0 and "horizon" in backtest_points.columns:
        one = backtest_points[backtest_points["horizon"] == 1].copy()
        if len(one) > 0:
            pred_1m_df = one.sort_values("target_month")[["target_month", "predicted_share"]].rename(
                columns={"target_month": "month"}
            )

    # 4ë¶„í•  ê·¸ë¦¼
    fig, axes = plt.subplots(2, 2, figsize=(16, 11))

    # (1) ì‹¤ì œ vs 1ê°œì›” ì• ì˜ˆì¸¡(ë°±í…ŒìŠ¤íŠ¸)
    ax = axes[0, 0]
    ax.plot(months, actual_share, marker="o", label="ì‹¤ì œ ì ìœ ìœ¨(%)", linewidth=2)
    if pred_1m_df is not None:
        ax.plot(
            pred_1m_df["month"].tolist(),
            pred_1m_df["predicted_share"].to_numpy(float),
            marker="o",
            linestyle="--",
            label="ì˜ˆì¸¡ ì ìœ ìœ¨(1ê°œì›” ì•, ë°±í…ŒìŠ¤íŠ¸)",
            linewidth=2,
            alpha=0.9,
        )
    ax.set_title(
        "GSì°¨ì§€ë¹„ ì‹œì¥ì ìœ ìœ¨(%)\n"
        "ì‹¤ì œê°’ vs '1ê°œì›” ì• ì˜ˆì¸¡'(Linear Regression ë¹„ìœ¨ ë°©ì‹, ë°±í…ŒìŠ¤íŠ¸)"
    )
    ax.set_xlabel("ì›”(YYYY-MM)")
    ax.set_ylabel("ì‹œì¥ì ìœ ìœ¨(%)  â€» 0~100, ê°’ì´ í´ìˆ˜ë¡ ì ìœ ìœ¨ì´ í¼")
    ax.grid(True, alpha=0.3)
    ax.legend()
    ax.tick_params(axis="x", rotation=45)

    # (2) Horizonë³„ ì ˆëŒ€ì˜¤ì°¨ ë¶„í¬(ë°•ìŠ¤í”Œë¡¯)
    ax = axes[0, 1]
    if len(backtest_points) > 0:
        horizons = sorted(summary_by_horizon.keys())
        data = [
            backtest_points[backtest_points["horizon"] == h]["abs_error_pp"].to_numpy(float)
            for h in horizons
        ]
        ax.boxplot(data, tick_labels=[f"{h}ê°œì›”" for h in horizons], showmeans=True)
        ax.set_title("ì˜ˆì¸¡ê¸°ê°„ë³„ ì˜¤ì°¨ ë¶„í¬\n(ì ˆëŒ€ì˜¤ì°¨: |ì˜ˆì¸¡-ì‹¤ì œ|, í¼ì„¼íŠ¸í¬ì¸íŠ¸ %p)")
        ax.set_xlabel("ëª‡ ê°œì›” ì•ì„ ì˜ˆì¸¡í–ˆëŠ”ì§€")
        ax.set_ylabel("ì ˆëŒ€ì˜¤ì°¨(%p)  â€» 0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì •í™•")
        ax.grid(True, alpha=0.3, axis="y")

        # ìš”ì•½ í…ìŠ¤íŠ¸(í•µì‹¬ë§Œ)
        lines = []
        for h in horizons:
            s = summary_by_horizon[h]
            rel = s.get("reliability_pct")
            rel_str = f"{rel:.1f}%" if rel is not None else "N/A"
            lines.append(f"{h}M: MAE {s['mae_pp']:.3f}%p, ì‹ ë¢°ë„ {rel_str}")
        ax.text(
            0.02,
            0.98,
            "\n".join(lines),
            transform=ax.transAxes,
            va="top",
            ha="left",
            fontsize=10,
            bbox=dict(boxstyle="round", facecolor="white", alpha=0.8),
        )
        ax.text(
            0.02,
            0.02,
            "ì˜ˆ: 0.20%p = ì ìœ ìœ¨ì´ í‰ê· ì ìœ¼ë¡œ 0.20ë§Œí¼(í¼ì„¼íŠ¸í¬ì¸íŠ¸) í‹€ë¦¼",
            transform=ax.transAxes,
            va="bottom",
            ha="left",
            fontsize=9,
            bbox=dict(boxstyle="round", facecolor="white", alpha=0.75),
        )
    else:
        ax.text(0.5, 0.5, "ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì—†ìŒ", ha="center", va="center")
        ax.axis("off")

    # (3) ì˜ˆì¸¡ vs ì‹¤ì œ ì‚°ì ë„ (y=x)
    ax = axes[1, 0]
    if len(backtest_points) > 0:
        y_true = backtest_points["actual_share"].to_numpy(float)
        y_pred = backtest_points["predicted_share"].to_numpy(float)
        ax.scatter(y_true, y_pred, alpha=0.6)
        mn = float(min(y_true.min(), y_pred.min()))
        mx = float(max(y_true.max(), y_pred.max()))
        ax.plot([mn, mx], [mn, mx], color="black", linestyle="--", linewidth=1)
        ax.set_title("ì˜ˆì¸¡ê°’ vs ì‹¤ì œê°’ (ì ìœ ìœ¨ %)\nì ì´ ëŒ€ê°ì„ (y=x)ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì •í™•")
        ax.set_xlabel("ì‹¤ì œ ì ìœ ìœ¨(%)")
        ax.set_ylabel("ì˜ˆì¸¡ ì ìœ ìœ¨(%)")
        ax.grid(True, alpha=0.3)
    else:
        ax.text(0.5, 0.5, "ë°ì´í„° ë¶€ì¡±", ha="center", va="center")
        ax.axis("off")

    # (4) ì”ì°¨(ì˜¤ì°¨) íˆìŠ¤í† ê·¸ë¨
    ax = axes[1, 1]
    if len(backtest_points) > 0:
        err = backtest_points["error_pp"].to_numpy(float)
        ax.hist(err, bins=12, color="#4C72B0", alpha=0.8)
        ax.axvline(0, color="black", linewidth=1)
        ax.set_title("ì˜¤ì°¨(ì˜ˆì¸¡-ì‹¤ì œ) ë¶„í¬\n0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì¢‹ìŒ (ì–‘ìˆ˜=ê³¼ëŒ€ì˜ˆì¸¡, ìŒìˆ˜=ê³¼ì†Œì˜ˆì¸¡)")
        ax.set_xlabel("ì˜¤ì°¨(%p)")
        ax.set_ylabel("ë¹ˆë„")
        ax.grid(True, alpha=0.3, axis="y")
    else:
        ax.text(0.5, 0.5, "ë°ì´í„° ë¶€ì¡±", ha="center", va="center")
        ax.axis("off")

    # ì „ì²´ ìš”ì•½ ë°•ìŠ¤ (ë¹„ì „ê³µììš©: í•œ ì¤„ë¡œ 'ì–¼ë§ˆë‚˜ í‹€ë¦¬ëŠ”ì§€' ì œì‹œ)
    if len(backtest_points) > 0:
        abs_err = np.abs(backtest_points["error_pp"].to_numpy(float))
        mae_all = float(np.mean(abs_err))
        p90 = float(np.percentile(abs_err, 90))
        fig.text(
            0.5,
            0.995,
            f"ìš”ì•½(ë°±í…ŒìŠ¤íŠ¸): í‰ê·  ì˜¤ì°¨(MAE) â‰ˆ {mae_all:.3f}%p, 90%ì˜ ê²½ìš° ì˜¤ì°¨ â‰¤ {p90:.3f}%p  (ê°’ì´ ì‘ì„ìˆ˜ë¡ ì •í™•)",
            ha="center",
            va="top",
            fontsize=11,
            bbox=dict(boxstyle="round", facecolor="white", alpha=0.9),
        )

    plt.tight_layout()
    plt.savefig(output_path, dpi=150, bbox_inches="tight")
    plt.close(fig)


def build_ml_result_txt(
    df: pd.DataFrame,
    rag_meta: Dict[str, Any],
    backtest_summary: Dict[str, Any],
    cv_summary: Dict[str, Any],
    output_path: str = "ml_result.txt",
):
    df = df.sort_values("month").reset_index(drop=True)

    period = rag_meta.get("period") or {
        "start": df["month"].iloc[0] if len(df) else None,
        "end": df["month"].iloc[-1] if len(df) else None,
        "n_months": int(len(df)),
    }
    missing_months = rag_meta.get("missing_months") or []

    lines: List[str] = []
    lines.append("=" * 80)
    lines.append("ML ê²°ê³¼ ìš”ì•½ (Linear Regression, RAG ê¸°ë°˜ í…ŒìŠ¤íŠ¸ì…‹)")
    lines.append("=" * 80)
    lines.append("")

    lines.append("1) ì´ ë¬¸ì„œê°€ ë§í•˜ëŠ” ê²ƒ (ë¹„ì „ê³µììš©)")
    lines.append("- ìš°ë¦¬ëŠ” 'ì‹œì¥ì ìœ ìœ¨'ì„ ì§ì ‘ ë§ì¶”ê¸°ë³´ë‹¤, **GS ì¶©ì „ê¸° ìˆ˜**ì™€ **ì‹œì¥ ì „ì²´ ì¶©ì „ê¸° ìˆ˜**ë¥¼ ê°ê° ë‹¨ìˆœ ì¶”ì„¸(ì§ì„ )ë¡œ ì˜ˆì¸¡í•œ ë’¤")
    lines.append("  ì ìœ ìœ¨ = (GS / ì‹œì¥ì „ì²´) Ã— 100 ìœ¼ë¡œ ê³„ì‚°í•˜ëŠ” ë°©ì‹ì„ í‰ê°€í–ˆìŠµë‹ˆë‹¤.")
    lines.append("- RAG(Knowledge Base)ì—ì„œ ì›”ë³„ ìˆ˜ì¹˜ë¥¼ ëŒì–´ì™€ **í…ŒìŠ¤íŠ¸ì…‹(ì •ë‹µ)**ìœ¼ë¡œ ì“°ê³ , ì—¬ëŸ¬ ë°©ì‹ìœ¼ë¡œ ì˜¤ì°¨ë¥¼ ì¸¡ì •í–ˆìŠµë‹ˆë‹¤.")
    lines.append("")

    lines.append("2) ë°ì´í„°(í…ŒìŠ¤íŠ¸ì…‹) ì¶œì²˜")
    lines.append(f"- ë°ì´í„° ì†ŒìŠ¤: {rag_meta.get('source', 'unknown')}")
    if rag_meta.get("knowledge_base_id") is not None:
        lines.append(f"- Knowledge Base ID: {rag_meta.get('knowledge_base_id', 'N/A')}")
    if rag_meta.get("model_id") is not None:
        lines.append(f"- ì‚¬ìš© ëª¨ë¸ ID: {rag_meta.get('model_id', 'N/A')}")
    if rag_meta.get("s3_bucket") is not None:
        lines.append(f"- S3 Bucket: {rag_meta.get('s3_bucket')}")
        lines.append(f"- S3 Prefix: {rag_meta.get('s3_prefix')}")
    lines.append(f"- ê¸°ê°„: {period.get('start')} ~ {period.get('end')} (ì´ {period.get('n_months')}ê°œì›”)")
    lines.append(f"- ê²€ì¦ ëª©í‘œ ê¸°ê°„(ìš”ì²­ ê¸°ì¤€): {DEFAULT_TEST_START_MONTH} ~ {DEFAULT_TEST_END_MONTH}")
    if missing_months:
        lines.append(f"- âš ï¸ RAGì—ì„œ ì¶”ì¶œ ì‹¤íŒ¨í•œ ì›”(ëˆ„ë½): {', '.join(missing_months)}")
    lines.append("")

    lines.append("3) í‰ê°€ ì§€í‘œ ì„¤ëª… (í•µì‹¬ë§Œ, ì‰¬ìš´ ë²„ì „)")
    lines.append("- MAE(%p): ì˜ˆì¸¡ ì ìœ ìœ¨ê³¼ ì‹¤ì œ ì ìœ ìœ¨ì˜ **í‰ê·  ì°¨ì´(ì ˆëŒ€ê°’)** ì…ë‹ˆë‹¤. ì˜ˆ: MAE 0.20%p â†’ í‰ê· ì ìœ¼ë¡œ 0.20%p ì •ë„ í‹€ë¦¼")
    lines.append("- MAPE(%): ì‹¤ì œ ëŒ€ë¹„ ì˜¤ì°¨ìœ¨ì˜ í‰ê· ì…ë‹ˆë‹¤. ì˜ˆ: MAPE 1.5% â†’ ì‹¤ì œê°’ì˜ 1.5%ë§Œí¼ í‰ê· ì ìœ¼ë¡œ í‹€ë¦¼")
    lines.append("- ì‹ ë¢°ë„(%): ì—¬ê¸°ì„œëŠ” ì´í•´ë¥¼ ë•ê¸° ìœ„í•´ **100 - MAPE** ë¡œ í‘œì‹œí–ˆìŠµë‹ˆë‹¤(í´ìˆ˜ë¡ ì¢‹ìŒ).")
    lines.append("- ì°¸ê³ : %p(í¼ì„¼íŠ¸í¬ì¸íŠ¸)ëŠ” 'í¼ì„¼íŠ¸ì˜ ì°¨ì´'ì…ë‹ˆë‹¤. ì˜ˆ: 16.0% â†’ 16.2% ëŠ” +0.2%p")
    lines.append("")

    lines.append("4) í…ŒìŠ¤íŠ¸ ë°©ë²•")
    lines.append("- ë¡¤ë§(rolling) ë°±í…ŒìŠ¤íŠ¸: ê¸°ì¤€ì›”ì„ ê³„ì† ë°”ê¾¸ë©° 'ê³¼ê±° ë°ì´í„°ë¡œ í•™ìŠµ â†’ ê·¸ ë‹¤ìŒ ë‹¬/ê·¸ ë‹¤ìŒ nê°œì›”ì„ ì˜ˆì¸¡'ì„ ë°˜ë³µ")
    lines.append("- ì‹œê³„ì—´ êµì°¨ê²€ì¦(TimeSeriesSplit): ì‹œê°„ ìˆœì„œë¥¼ ì§€í‚¤ëŠ” ë°©ì‹ìœ¼ë¡œ í•™ìŠµ/ê²€ì¦ì„ ì—¬ëŸ¬ ë²ˆ ë°˜ë³µ")
    lines.append("- ì‚¬ìš©í•œ ì˜ˆì¸¡ ë¡œì§(í˜„ì¬ ì½”ë“œì™€ ë™ì¼í•œ ì•„ì´ë””ì–´):")
    lines.append("  1) GS ì´ì¶©ì „ê¸° ìˆ˜ë¥¼ Linear Regressionìœ¼ë¡œ ì˜ˆì¸¡")
    lines.append("  2) ì‹œì¥ ì „ì²´ ì´ì¶©ì „ê¸° ìˆ˜ë¥¼ Linear Regressionìœ¼ë¡œ ì˜ˆì¸¡")
    lines.append("  3) ì ìœ ìœ¨(%) = (ì˜ˆì¸¡ GS / ì˜ˆì¸¡ ì‹œì¥ì „ì²´) Ã— 100")
    lines.append("- ì‚¬ìš©í•œ íŒŒë¼ë¯¸í„°(í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸/í…ŒìŠ¤íŠ¸ ê¸°ì¤€): ì˜ˆì¸¡ê¸°ê°„ 1~8ê°œì›”, ìµœì†Œ í•™ìŠµ 3ê°œì›”")
    lines.append("- ì°¸ê³ (ì‹œë®¬ë ˆì´í„° ì…ë ¥ í•œê³„): ìµœëŒ€ ì˜ˆì¸¡ê¸°ê°„ 8ê°œì›”, ìµœëŒ€ ì¶”ê°€ ì„¤ì¹˜ ì¶©ì „ê¸° 9,000ëŒ€")
    lines.append("")

    lines.append("5) ê²°ê³¼ ìš”ì•½")
    overall = backtest_summary.get("overall", {})
    if overall:
        lines.append(f"- ì „ì²´(ëª¨ë“  í…ŒìŠ¤íŠ¸ í•©ì‚°):")
        lines.append(f"  - í…ŒìŠ¤íŠ¸ ìˆ˜: {overall.get('n_tests')}ê°œ")
        lines.append(f"  - MAE: {overall.get('mae_pp')}%p")
        lines.append(f"  - RMSE: {overall.get('rmse_pp')}%p")
        lines.append(f"  - MAPE: {overall.get('mape_pct')}%")
        lines.append(f"  - ì‹ ë¢°ë„(=100-MAPE): {overall.get('reliability_pct')}%")
        try:
            rel = float(overall.get("reliability_pct"))
            mae = float(overall.get("mae_pp"))
            lines.append(f"  - í•œ ì¤„ ê²°ë¡ : í‰ê· ì ìœ¼ë¡œ **ì•½ {mae:.3f}%p ì •ë„** í‹€ë¦¬ë©°, ì‹ ë¢°ë„(100-MAPE)ëŠ” **ì•½ {rel:.1f}%** ìˆ˜ì¤€ì…ë‹ˆë‹¤.")
        except Exception:
            pass
    else:
        lines.append("- ì „ì²´ ìš”ì•½ì„ ë§Œë“¤ ìˆ˜ ì—†ì—ˆìŠµë‹ˆë‹¤(ë°ì´í„°/í…ŒìŠ¤íŠ¸ ë¶€ì¡±).")

    lines.append("")
    lines.append("- ì˜ˆì¸¡ê¸°ê°„(ëª‡ ê°œì›” ì•ì„ ë§ì¶”ëŠ”ì§€)ë³„ ìš”ì•½:")
    lines.append("  | ì˜ˆì¸¡ê¸°ê°„ | í…ŒìŠ¤íŠ¸ìˆ˜ | MAE(%p) | RMSE(%p) | MAPE(%) | ì‹ ë¢°ë„(%) | ìµœì•…ì˜¤ì°¨(%p) |")
    lines.append("  |---:|---:|---:|---:|---:|---:|---:|")

    by_h = backtest_summary.get("summary_by_horizon", {})
    for h in sorted(by_h.keys()):
        s = by_h[h]
        lines.append(
            "  | {h} | {n} | {mae} | {rmse} | {mape} | {rel} | {worst} |".format(
                h=f"{h}ê°œì›”",
                n=s.get("n_tests"),
                mae=s.get("mae_pp"),
                rmse=s.get("rmse_pp"),
                mape=s.get("mape_pct") if s.get("mape_pct") is not None else "N/A",
                rel=s.get("reliability_pct") if s.get("reliability_pct") is not None else "N/A",
                worst=s.get("worst_abs_error_pp"),
            )
        )

    lines.append("")
    lines.append("- ì‹œê³„ì—´ êµì°¨ê²€ì¦(TimeSeriesSplit) ìš”ì•½:")
    if cv_summary:
        lines.append(f"  - Fold ìˆ˜: {cv_summary.get('n_splits')}")
        lines.append(f"  - í‰ê°€ í¬ì¸íŠ¸ ìˆ˜: {cv_summary.get('n_points')}")
        lines.append(f"  - MAE: {cv_summary.get('mae_pp')}%p")
        lines.append(f"  - RMSE: {cv_summary.get('rmse_pp')}%p")
        lines.append(f"  - MAPE: {cv_summary.get('mape_pct')}%")
        lines.append(f"  - ì‹ ë¢°ë„(=100-MAPE): {cv_summary.get('reliability_pct')}%")
    else:
        lines.append("  - ê³„ì‚° ë¶ˆê°€")

    lines.append("")
    lines.append("6) í•´ì„ & ì£¼ì˜ì‚¬í•­")
    lines.append("- ì´ ë°©ì‹ì€ 'ì§ì„  ì¶”ì„¸'ë¥¼ ê°€ì •í•©ë‹ˆë‹¤. ì‹œì¥ì´ ê°‘ìê¸° ë³€í•˜ê±°ë‚˜(ì •ì±…/ëŒ€í˜•ì‚¬ì—…ì ì¦ì„¤ ë“±) ê³„ì ˆì„±ì´ í¬ë©´ ì˜¤ì°¨ê°€ ì»¤ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    lines.append("- RAGì—ì„œ ìˆ«ìë¥¼ ì¶”ì¶œí•  ë•ŒëŠ” ë¬¸ì„œ ì¡°ê°/ìš”ì•½ì— ë”°ë¼ ëˆ„ë½ë  ìˆ˜ ìˆì–´, ì›”ë³„ ë°ì´í„°ê°€ ì¶©ë¶„íˆ í™•ë³´ë˜ëŠ”ì§€ í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.")
    lines.append("- ë³¸ ê²°ê³¼ëŠ” 'í˜„ì¬ êµ¬í˜„ëœ ë¡œì§/íŒŒë¼ë¯¸í„°' ê¸°ì¤€ì˜ ì •í•©ì„± ì ê²€ì´ë©°, **ë³µì¡í•œ ëª¨ë¸ ì—†ì´ë„** ì–´ëŠ ì •ë„ ì˜¤ì°¨ë¡œ ë™ì‘í•˜ëŠ”ì§€ ë³´ì—¬ì¤ë‹ˆë‹¤.")
    lines.append("- í˜„ì¬ ê²°ê³¼ í•´ì„(ìš”ì•½):")
    lines.append("  - 1~3ê°œì›” ì• ì˜ˆì¸¡ì€ í‰ê·  ì˜¤ì°¨ê°€ ìƒëŒ€ì ìœ¼ë¡œ ì‘ê³ (ì•½ 0.16~0.25%p), ì‹ ë¢°ë„(100-MAPE)ë„ ë†’ê²Œ ë‚˜ì˜µë‹ˆë‹¤.")
    lines.append("  - 4~6ê°œì›”ë¡œ ê°ˆìˆ˜ë¡ ì˜¤ì°¨ê°€ ì»¤ì§€ëŠ” ê²½í–¥ì´ ìˆì–´, ì¥ê¸° ì˜ˆì¸¡ì€ 'ì°¸ê³ ìš©'ìœ¼ë¡œ ë‘ê³  ë‹¨ê¸°(1~3ê°œì›”) ì¤‘ì‹¬ í™œìš©ì´ ì•ˆì „í•©ë‹ˆë‹¤.")
    lines.append("  - 7~8ê°œì›” ì˜ˆì¸¡ì€ í‘œë³¸ ìˆ˜ê°€ ì ì–´(í…ŒìŠ¤íŠ¸ íšŸìˆ˜ê°€ ì ìŒ) ì§€í‘œê°€ í”ë“¤ë¦´ ìˆ˜ ìˆìœ¼ë‹ˆ, ìˆ˜ì¹˜ ìì²´ë³´ë‹¤ëŠ” 'ëŒ€ëµì ì¸ ì°¸ê³ 'ë¡œ ë³´ì‹œëŠ” ê²ƒì´ ì•ˆì „í•©ë‹ˆë‹¤.")
    lines.append("")
    lines.append("7) ì°¸ê³ : ê¸°ì¡´ ì¢…í•© ë¶„ì„(lr_analysis_*)ê³¼ì˜ ì¼ê´€ì„±")
    lines.append("- lr_analysis_report.txt / lr_analysis_plots.pngì˜ ê²°ë¡  ìš”ì•½: Ratio ë°©ì‹ì´ Direct ë°©ì‹ë³´ë‹¤ ì˜¤ì°¨ê°€ ì‘ê³ (ì•½ 15% ê°œì„ ),")
    lines.append("  ì‹œì¥ ì „ì²´ê°€ ë§¤ìš° ì„ í˜•(RÂ²â‰ˆ0.98)ì´ë¼ ì ìœ ìœ¨(ë¹„ìœ¨)ì€ ë” ì•ˆì •ì ìœ¼ë¡œ ì˜ˆì¸¡ë¨(RÂ²â‰ˆ0.96).")
    lines.append("- ë³¸ ml_resultì˜ ë°±í…ŒìŠ¤íŠ¸ë„ ë™ì¼í•œ ë°©í–¥(ë‹¨ê¸°ì¼ìˆ˜ë¡ ë” ì •í™•, Ratio ê¸°ë°˜ ì ìœ ìœ¨ì€ ì‘ì€ %p ì˜¤ì°¨)ì„ ë³´ì´ë©°,")
    lines.append("  ì„¤ì •ì´ 8ê°œì›”/9000ëŒ€ë¡œ í™•ì¥ë˜ë”ë¼ë„ 'ê¸°ë³¸ ì˜ˆì¸¡ ë¡œì§(LinearRegression + Ratio)'ì˜ ì •í•©ì„±ì€ ìœ ì§€ë©ë‹ˆë‹¤.")
    lines.append("")

    lines.append("8) ìƒì„±ëœ íŒŒì¼")
    lines.append("- ml_result.png: í•µì‹¬ ê·¸ë˜í”„ 1ì¥(ì‹¤ì œvsì˜ˆì¸¡, ê¸°ê°„ë³„ ì˜¤ì°¨ ë¶„í¬, ì‚°ì ë„, ì”ì°¨ë¶„í¬)")
    lines.append("- ml_result.txt: ì´ ë¬¸ì„œ")
    lines.append("")

    lines.append("(ì¬í˜„) python ml_rag_evaluation_report.py")

    with open(output_path, "w", encoding="utf-8") as f:
        f.write("\n".join(lines))


# -----------------------------
# main
# -----------------------------


def main() -> int:
    print("\n" + "=" * 80)
    print("ğŸš€ RAG ê¸°ë°˜ ML í‰ê°€ ë¦¬í¬íŠ¸ ìƒì„±")
    print("=" * 80)

    # 1) RAGì—ì„œ ì‹œê³„ì—´ ì¶”ì¶œ
    print("\n1) RAG(Knowledge Base)ì—ì„œ ì›”ë³„ ì‹œê³„ì—´ ë°ì´í„° ì¶”ì¶œ ì¤‘...")
    extractor = RAGTimeSeriesExtractor()
    target_months = generate_month_range(DEFAULT_TEST_START_MONTH, DEFAULT_TEST_END_MONTH)
    df, meta = extractor.build_timeseries(months=target_months)

    # KB ê¸°ë°˜ ì¶”ì¶œì´ ì›” ëˆ„ë½/ì‹¤íŒ¨í•˜ëŠ” ê²½ìš°ê°€ ìˆì–´,
    # í”„ë¡œì íŠ¸ì—ì„œ ì‹¤ì œ ìš´ì˜ì— ì“°ëŠ” S3 ë¡œë”ë¡œ ë™ì¼ ê¸°ê°„ ë°ì´í„°ë¥¼ ë³´ê°•/ëŒ€ì²´í•©ë‹ˆë‹¤.
    missing = meta.get("missing_months") or []
    if df.empty or len(df) < 6 or len(missing) > 0:
        print(f"   âš ï¸ KB ê¸°ë°˜ ì¶”ì¶œì´ ë¶ˆì™„ì „í•©ë‹ˆë‹¤. (ì„±ê³µ {len(df)}ê°œì›”, ëˆ„ë½ {len(missing)}ê°œì›”)")
        print("   ğŸ”„ S3 ë¡œë” ê¸°ë°˜ìœ¼ë¡œ ë™ì¼ ê¸°ê°„ ë°ì´í„°ë¥¼ êµ¬ì„±í•´ ì¬ì‹œë„í•©ë‹ˆë‹¤...")
        df2, meta2 = build_timeseries_from_s3(target_months)
        if not df2.empty and len(df2) >= len(df):
            meta2["kb_attempted"] = True
            meta2["kb_extracted_months"] = int(len(df))
            meta2["kb_missing_months"] = missing
            df, meta = df2, meta2

    if df.empty or len(df) < 6:
        print("âŒ RAGë¡œ ì¶©ë¶„í•œ ì›”ë³„ ë°ì´í„°ë¥¼ ë§Œë“¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        print("   - KB ê²€ìƒ‰/ë¬¸ì„œ êµ¬ì¡°/ìê²©ì¦ëª…/ë„¤íŠ¸ì›Œí¬ ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        print("   - ìµœì†Œ 6ê°œì›” ì´ìƒ ë°ì´í„°ê°€ ìˆì–´ì•¼ í…ŒìŠ¤íŠ¸ê°€ ì•ˆì •ì ì…ë‹ˆë‹¤.")
        return 1

    src = meta.get("source", "unknown")
    print(f"âœ… ì¶”ì¶œ ì™„ë£Œ: {len(df)}ê°œì›” ({df['month'].iloc[0]} ~ {df['month'].iloc[-1]}) / source={src}")

    # 2) í‰ê°€ ìˆ˜í–‰
    print("\n2) Linear Regression(ë¹„ìœ¨ ë°©ì‹) í‰ê°€ ìˆ˜í–‰ ì¤‘...")
    evaluator = LinearRegressionRatioEvaluator(df)

    backtest = evaluator.rolling_backtest(horizons=[1, 2, 3, 4, 5, 6, 7, 8])
    cv = evaluator.timeseries_cv(n_splits=5)

    # 3) ê²°ê³¼ íŒŒì¼ ìƒì„±
    print("\n3) ê²°ê³¼ íŒŒì¼ ìƒì„± ì¤‘...")
    build_ml_result_png(
        df=df,
        backtest_points=backtest["backtest_points"],
        summary_by_horizon=backtest["summary_by_horizon"],
        output_path="ml_result.png",
    )
    build_ml_result_txt(
        df=df,
        rag_meta=meta,
        backtest_summary={
            "overall": backtest.get("overall", {}),
            "summary_by_horizon": backtest.get("summary_by_horizon", {}),
        },
        cv_summary=cv,
        output_path="ml_result.txt",
    )

    print("âœ… ìƒì„± ì™„ë£Œ: ml_result.png, ml_result.txt")
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
