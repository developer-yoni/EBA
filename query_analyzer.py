"""
ì»¤ìŠ¤í…€ ì§ˆì˜ ë¶„ì„ ë° ì°¨íŠ¸ ìƒì„± ëª¨ë“ˆ
- RAG ì—°ë™
- í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§
- ì½”ë“œ ì¸í„°í”„ë¦¬í„° ì—°ë™
"""
import json
import re
import boto3
import pandas as pd
from config import Config
from chart_generator import ChartGenerator

class QueryAnalyzer:
    """ì§ˆì˜ ë¶„ì„ ë° ë™ì  ì°¨íŠ¸ ìƒì„±"""
    
    def __init__(self):
        self.bedrock_client = boto3.client(
            'bedrock-runtime',
            region_name=Config.AWS_REGION,
            aws_access_key_id=Config.AWS_ACCESS_KEY_ID,
            aws_secret_access_key=Config.AWS_SECRET_ACCESS_KEY
        )
        self.kb_client = boto3.client(
            'bedrock-agent-runtime',
            region_name=Config.AWS_REGION,
            aws_access_key_id=Config.AWS_ACCESS_KEY_ID,
            aws_secret_access_key=Config.AWS_SECRET_ACCESS_KEY
        )
        self.chart_generator = ChartGenerator()
    
    def retrieve_from_kb(self, query: str) -> str:
        """Knowledge Baseì—ì„œ ê´€ë ¨ ì •ë³´ ê²€ìƒ‰ (RAG)"""
        try:
            response = self.kb_client.retrieve(
                knowledgeBaseId=Config.KNOWLEDGE_BASE_ID,
                retrievalQuery={'text': query},
                retrievalConfiguration={
                    'vectorSearchConfiguration': {
                        'numberOfResults': Config.KB_NUMBER_OF_RESULTS
                    }
                }
            )
            
            results = response.get('retrievalResults', [])
            
            # RAG ê²€ìƒ‰ ê²°ê³¼ ìƒì„¸ ë¡œê¹…
            print(f'   â””â”€ ğŸ” RAG ê²€ìƒ‰ ê²°ê³¼: {len(results)}ê°œ ë¬¸ì„œ ê²€ìƒ‰ë¨', flush=True)
            
            if not results:
                print(f'      â””â”€ âš ï¸ ê´€ë ¨ ë¬¸ì„œ ì—†ìŒ', flush=True)
                return ''
            
            for i, r in enumerate(results):
                score = r.get('score', 0)
                location = r.get('location', {})
                s3_uri = location.get('s3Location', {}).get('uri', 'N/A')
                content_preview = r.get('content', {}).get('text', '')[:100]
                print(f'      [{i+1}] ê´€ë ¨ë„: {score:.4f}', flush=True)
                print(f'          ì†ŒìŠ¤: {s3_uri}', flush=True)
                print(f'          ë‚´ìš©: {content_preview}...', flush=True)
            
            context = '\n\n'.join([
                f"[ì°¸ê³ ìë£Œ {i+1}] (ê´€ë ¨ë„: {r.get('score', 0):.2f})\n{r.get('content', {}).get('text', '')}"
                for i, r in enumerate(results)
            ])
            
            return context
        except Exception as e:
            print(f'   â””â”€ âŒ KB ê²€ìƒ‰ ì˜¤ë¥˜: {e}', flush=True)
            return ''
    
    def analyze_query_intent(self, query: str, available_data: dict) -> dict:
        """ì§ˆì˜ ì˜ë„ ë¶„ì„ - Multi-Step Reasoning + Semantic Column Matching"""
        
        analysis_prompt = f"""
ë‹¹ì‹ ì€ ë°ì´í„° ë¶„ì„ ì§ˆì˜ë¥¼ ì •í™•í•˜ê²Œ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ì§ˆì˜ë¥¼ ë¶„ì„í•˜ì—¬ ì–´ë–¤ ë°ì´í„°ë¥¼ ì–´ë–¤ í˜•ì‹ìœ¼ë¡œ ë³´ì—¬ì¤„ì§€ ê²°ì •í•©ë‹ˆë‹¤.

## ğŸš¨ ë§¤ìš° ì¤‘ìš”: ì¶œë ¥ í˜•ì‹ ê²°ì • ê·œì¹™

### ì‹œê°í™”(ì°¨íŠ¸/ê·¸ë˜í”„)ê°€ í•„ìš”í•œ ê²½ìš° (needs_chart: true)
ë‹¤ìŒ í‚¤ì›Œë“œê°€ **ëª…ì‹œì ìœ¼ë¡œ** í¬í•¨ëœ ê²½ìš°ì—ë§Œ ì°¨íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤:
- "ê·¸ë˜í”„", "ì°¨íŠ¸", "ì‹œê°í™”", "ê·¸ë ¤ì¤˜", "ë§‰ëŒ€", "ì›í˜•", "íŒŒì´", "ì„ í˜•", "ë¼ì¸"
- ì˜ˆ: "ë§‰ëŒ€ê·¸ë˜í”„ë¡œ ë³´ì—¬ì¤˜", "ì›í˜• ì°¨íŠ¸ë¡œ ê·¸ë ¤ì¤˜", "ì‹œê°í™”í•´ì¤˜"

### í‘œ(í…Œì´ë¸”) í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•˜ëŠ” ê²½ìš° (needs_chart: false) - ê¸°ë³¸ê°’!
ë‹¤ìŒ ê²½ìš°ì—ëŠ” ì°¨íŠ¸ ì—†ì´ **í‘œ(í…Œì´ë¸”) í˜•ì‹**ìœ¼ë¡œ ë‹µë³€í•©ë‹ˆë‹¤:
- "í‘œ", "í…Œì´ë¸”", "ëª©ë¡", "ë¦¬ìŠ¤íŠ¸" í‚¤ì›Œë“œê°€ ìˆëŠ” ê²½ìš°
- ì‹œê°í™” ê´€ë ¨ í‚¤ì›Œë“œê°€ **ì „í˜€ ì—†ëŠ”** ê²½ìš° (ê¸°ë³¸ê°’)
- "í‘œë¡œ ë³´ì—¬ì¤˜", "ëª©ë¡ìœ¼ë¡œ ì•Œë ¤ì¤˜" ë“±

### í‘œë„ ì°¨íŠ¸ë„ í•„ìš” ì—†ëŠ” ê²½ìš° (needs_chart: false, show_table: false)
- "í‘œ ì—†ì´", "í‘œ ë§ê³ ", "í…ìŠ¤íŠ¸ë¡œë§Œ", "ê°„ë‹¨íˆ" ë“±ì˜ í‘œí˜„ì´ ìˆëŠ” ê²½ìš°

âš ï¸ ì£¼ì˜: "ì›í˜• í‘œ"ëŠ” "ì›í˜• ê·¸ë˜í”„"ê°€ ì•„ë‹™ë‹ˆë‹¤! "í‘œ"ê°€ í¬í•¨ë˜ë©´ í…Œì´ë¸” í˜•ì‹ì…ë‹ˆë‹¤.

## ì‚¬ìš©ì ì§ˆì˜
{query}

## ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ (ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼)

### ê¸°ë³¸ ìˆ˜ëŸ‰ ì»¬ëŸ¼ (ì ˆëŒ€ê°’)
| ì»¬ëŸ¼ëª… | ì„¤ëª… | ë°ì´í„° íƒ€ì… |
|--------|------|------------|
| ì¶©ì „ì†Œìˆ˜ | ì¶©ì „ì†Œ ê°œìˆ˜ | ì •ìˆ˜ (ì˜ˆ: 1000, 2000) |
| ì™„ì†ì¶©ì „ê¸° | ì™„ì†ì¶©ì „ê¸° ê°œìˆ˜ | ì •ìˆ˜ (ì˜ˆ: 5000, 10000) |
| ê¸‰ì†ì¶©ì „ê¸° | ê¸‰ì†ì¶©ì „ê¸° ê°œìˆ˜ | ì •ìˆ˜ (ì˜ˆ: 1000, 2000) |
| ì´ì¶©ì „ê¸° | ì´ì¶©ì „ê¸° ê°œìˆ˜ | ì •ìˆ˜ (ì˜ˆ: 6000, 12000) |

### ì¦ê° ì»¬ëŸ¼ (ì „ì›” ëŒ€ë¹„ ë³€í™”ëŸ‰, ì–‘ìˆ˜/ìŒìˆ˜)
| ì»¬ëŸ¼ëª… | ì„¤ëª… | ë°ì´í„° íƒ€ì… |
|--------|------|------------|
| ì¶©ì „ì†Œì¦ê° | ì „ì›” ëŒ€ë¹„ ì¶©ì „ì†Œ ì¦ê°ëŸ‰ | ì •ìˆ˜ (ì˜ˆ: +50, -10) |
| ì™„ì†ì¦ê° | ì „ì›” ëŒ€ë¹„ ì™„ì†ì¶©ì „ê¸° ì¦ê°ëŸ‰ | ì •ìˆ˜ (ì˜ˆ: +100, -50) |
| ê¸‰ì†ì¦ê° | ì „ì›” ëŒ€ë¹„ ê¸‰ì†ì¶©ì „ê¸° ì¦ê°ëŸ‰ | ì •ìˆ˜ (ì˜ˆ: +30, -20) |
| ì´ì¦ê° | ì „ì›” ëŒ€ë¹„ ì´ì¶©ì „ê¸° ì¦ê°ëŸ‰ | ì •ìˆ˜ (ì˜ˆ: +130, -70) |

### ë¹„ìœ¨/ìˆœìœ„ ì»¬ëŸ¼
| ì»¬ëŸ¼ëª… | ì„¤ëª… | ë°ì´í„° íƒ€ì… |
|--------|------|------------|
| ì‹œì¥ì ìœ ìœ¨ | ì „ì²´ ëŒ€ë¹„ ì ìœ ìœ¨ | ë°±ë¶„ìœ¨ (ì˜ˆ: 15.5%) |
| ìˆœìœ„ | ì‹œì¥ì ìœ ìœ¨ ìˆœìœ„ | ì •ìˆ˜ (ì˜ˆ: 1, 2, 3) |
| ìˆœìœ„ë³€ë™ | ì „ì›” ëŒ€ë¹„ ìˆœìœ„ ë³€ë™ | ì •ìˆ˜ (ì˜ˆ: +1, -2) |

### ì‹ë³„ ì»¬ëŸ¼
| ì»¬ëŸ¼ëª… | ì„¤ëª… |
|--------|------|
| CPOëª… | ì¶©ì „ì‚¬ì—…ìëª… (ì˜ˆ: GSì°¨ì§€ë¹„, íŒŒì›Œíë¸Œ) |
| snapshot_month | ê¸°ì¤€ ì—°ì›” (ì˜ˆ: 2025-10) |

## ğŸ”‘ ë§¤ìš° ì¤‘ìš”: "ì „ì²´ CPO" ìš©ì–´ ì´í•´ (ì—‘ì…€ ì…€ ìœ„ì¹˜ ê¸°ë°˜)

### "ì „ì²´ CPO" ë˜ëŠ” "ì¶©ì „ì‚¬ì—…ì" í‚¤ì›Œë“œ ì²˜ë¦¬ (ëŒ€ì†Œë¬¸ì/ê³µë°± ë¬´ì‹œ)
ë‹¤ìŒ í‘œí˜„ë“¤ì€ ëª¨ë‘ **ì „ì²´ í•©ê³„ ë°ì´í„°**ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤:
- "ì „ì²´ CPO", "ì „ì²´CPO", "ì „ì²´cpo", "ì „ì²´ cpo"
- "ì „ì²´ ì¶©ì „ì‚¬ì—…ì", "ì „ì²´ì¶©ì „ì‚¬ì—…ì", "ì¶©ì „ì‚¬ì—…ì"
- "CPO ê°œìˆ˜", "ì¶©ì „ì‚¬ì—…ì ê°œìˆ˜", "ì¶©ì „ì‚¬ì—…ì ìˆ˜"

### ì—‘ì…€ ì…€ ìœ„ì¹˜ ë§¤í•‘ (L3:P4 ë²”ìœ„)

#### ì „ì²´ í˜„í™© (3í–‰ = ì „ì²´CPO í–‰)
| ì§ˆì˜ í‘œí˜„ | ì—‘ì…€ ì…€ | ë§¤í•‘ ì»¬ëŸ¼ |
|-----------|---------|-----------|
| ì „ì²´ CPO ê°œìˆ˜, ì¶©ì „ì‚¬ì—…ì ê°œìˆ˜ | L3 | total_cpos |
| ì „ì²´ ì¶©ì „ì†Œ ê°œìˆ˜ | M3 | total_stations |
| ì „ì²´ ì™„ì†ì¶©ì „ê¸° ê°œìˆ˜ | N3 | total_slow_chargers |
| ì „ì²´ ê¸‰ì†ì¶©ì „ê¸° ê°œìˆ˜ | O3 | total_fast_chargers |
| ì „ì²´ ì¶©ì „ê¸° ê°œìˆ˜ | P3 | total_chargers |

#### ë‹¹ì›” ì¦ê°ëŸ‰ (4í–‰ = ë‹¹ì›”ì¦ê°ëŸ‰ í–‰)
| ì§ˆì˜ í‘œí˜„ | ì—‘ì…€ ì…€ | ë§¤í•‘ ì»¬ëŸ¼ |
|-----------|---------|-----------|
| ì „ì²´ CPO ë‹¹ì›” ì¦ê°ëŸ‰ | L4 | change_cpos |
| ì „ì²´ ì¶©ì „ì†Œ ë‹¹ì›” ì¦ê°ëŸ‰ | M4 | change_stations |
| ì „ì²´ ì™„ì†ì¶©ì „ê¸° ë‹¹ì›” ì¦ê°ëŸ‰ | N4 | change_slow_chargers |
| ì „ì²´ ê¸‰ì†ì¶©ì „ê¸° ë‹¹ì›” ì¦ê°ëŸ‰ | O4 | change_fast_chargers |
| ì „ì²´ ì¶©ì „ê¸° ë‹¹ì›” ì¦ê°ëŸ‰ | P4 | change_total_chargers |

### ì¤‘ìš” ê·œì¹™:
1. "ì „ì²´ CPO"ëŠ” ëª¨ë“  CPOë¥¼ ë‚˜ì—´í•˜ëŠ” ê²ƒì´ **ì•„ë‹™ë‹ˆë‹¤**!
2. "ì „ì²´ CPO"ëŠ” ì—‘ì…€ ìš”ì•½ í–‰(L3:P4)ì˜ í•©ê³„ ë°ì´í„°ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤
3. cpo_name: "ì „ì²´"ë¡œ ì„¤ì •í•˜ë©´ ì—‘ì…€ ìš”ì•½ í–‰ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤
4. display_columnì— ìœ„ ë§¤í•‘ ì»¬ëŸ¼ëª…ì„ ì‚¬ìš©í•©ë‹ˆë‹¤

### ì˜ˆì‹œ:
- "ì „ì²´ CPO ê°œìˆ˜ ë³€í™”" â†’ cpo_name: "ì „ì²´", display_column: "total_cpos"
- "ì „ì²´ ì™„ì†ì¶©ì „ê¸° ì¦ê°€ëŸ‰" â†’ cpo_name: "ì „ì²´", display_column: "change_slow_chargers"
- "ì „ì²´ ê¸‰ì†ì¶©ì „ê¸° ë‹¹ì›” ì¦ê°ëŸ‰" â†’ cpo_name: "ì „ì²´", display_column: "change_fast_chargers"

## âš ï¸ ì¤‘ìš”: ë°ì´í„°ì— ì—†ëŠ” í•­ëª©
ë‹¤ìŒ í•­ëª©ë“¤ì€ ë°ì´í„°ë² ì´ìŠ¤ì— **ì§ì ‘ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤**:
- "ì¦ê°€ë¥ ", "ì¦ê°€ìœ¨", "ì„±ì¥ë¥ " â†’ ê³„ì‚° í•„ìš” (ì¦ê°ëŸ‰ / ì´ì „ê°’ * 100)
- "ê°ì†Œë¥ ", "ê°ì†Œìœ¨" â†’ ê³„ì‚° í•„ìš”
- "ì ìœ ìœ¨ ë³€ë™" â†’ ì§ì ‘ ì»¬ëŸ¼ ì—†ìŒ

## ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°
- ê¸°ê°„: {available_data.get('available_months', [])}
- CPO ìˆ˜: {len(available_data.get('available_cpos', []))}ê°œ
- ì‹¤ì œ ì»¬ëŸ¼: {available_data.get('available_columns', [])}

---
## Multi-Step Reasoning ë¶„ì„ ê³¼ì •

### Step 1: ì§ˆì˜ í•µì‹¬ ìš”ì†Œ ì¶”ì¶œ
ì‚¬ìš©ì ì§ˆì˜ì—ì„œ ë‹¤ìŒì„ ì‹ë³„í•˜ì„¸ìš”:
- ëŒ€ìƒ: ë¬´ì—‡ì— ëŒ€í•œ ì§ˆì˜ì¸ê°€? (ì™„ì†ì¶©ì „ê¸°, ê¸‰ì†ì¶©ì „ê¸°, ì¶©ì „ì†Œ ë“±)
- ì¸¡ì •ê°’: ì–´ë–¤ ê°’ì„ ë³´ê³  ì‹¶ì€ê°€? (ê°œìˆ˜, ì¦ê°ëŸ‰, ì¦ê°€ë¥ , ì ìœ ìœ¨ ë“±)
- ì¡°ê±´: ê¸°ê°„, íŠ¹ì • CPO, ìƒìœ„/í•˜ìœ„ ëª‡ ê°œ ë“±
- **CPO ë²”ìœ„**: 
  - "ì „ì²´ CPO", "ì¶©ì „ì‚¬ì—…ì ê°œìˆ˜", "CPO ê°œìˆ˜" â†’ cpo_name: "ì „ì²´" (ìš”ì•½ í–‰ ë°ì´í„°)
  - "GSì°¨ì§€ë¹„", "ì—ë²„ì˜¨" ë“± íŠ¹ì • CPOëª… â†’ cpo_name: í•´ë‹¹ CPOëª…
  - CPOëª… ì–¸ê¸‰ ì—†ìŒ â†’ cpo_name: null (ì „ì²´ ë˜ëŠ” ìƒìœ„ Nê°œ)
- ì¶œë ¥í˜•ì‹: 
  - "chart" = ì°¨íŠ¸/ê·¸ë˜í”„ í‚¤ì›Œë“œê°€ ëª…ì‹œì ìœ¼ë¡œ ìˆìŒ
  - "table" = í‘œ/í…Œì´ë¸” í‚¤ì›Œë“œê°€ ìˆê±°ë‚˜, ì‹œê°í™” í‚¤ì›Œë“œê°€ ì—†ìŒ (ê¸°ë³¸ê°’)
  - "text_only" = í‘œë„ í•„ìš” ì—†ë‹¤ê³  ëª…ì‹œí•¨

### Step 2: ì¸¡ì •ê°’ â†’ ì»¬ëŸ¼ ë§¤í•‘ (Semantic Matching)
ì‚¬ìš©ìê°€ ìš”ì²­í•œ "ì¸¡ì •ê°’"ì„ ì‹¤ì œ ì»¬ëŸ¼ì— ë§¤í•‘í•©ë‹ˆë‹¤.

**ì§ì ‘ ë§¤í•‘ ê°€ëŠ¥í•œ ê²½ìš°:**
| ì‚¬ìš©ì í‘œí˜„ | ë§¤í•‘ ì»¬ëŸ¼ | í™•ì‹ ë„ |
|------------|----------|--------|
| "ì™„ì†ì¶©ì „ê¸° ê°œìˆ˜", "ì™„ì† ìˆ˜" | ì™„ì†ì¶©ì „ê¸° | HIGH |
| "ì™„ì†ì¶©ì „ê¸° ì¦ê°ëŸ‰", "ì™„ì† ì¦ê°€ëŸ‰" | ì™„ì†ì¦ê° | HIGH |
| "ê¸‰ì†ì¶©ì „ê¸° ê°œìˆ˜" | ê¸‰ì†ì¶©ì „ê¸° | HIGH |
| "ê¸‰ì†ì¶©ì „ê¸° ì¦ê°ëŸ‰" | ê¸‰ì†ì¦ê° | HIGH |
| "ì‹œì¥ì ìœ ìœ¨", "ì ìœ ìœ¨" | ì‹œì¥ì ìœ ìœ¨ | HIGH |
| "ì¶©ì „ì†Œ ìˆ˜", "ì¶©ì „ì†Œ ê°œìˆ˜" | ì¶©ì „ì†Œìˆ˜ | HIGH |
| "ì¶©ì „ì†Œ ì¦ê°ëŸ‰" | ì¶©ì „ì†Œì¦ê° | HIGH |

**ê³„ì‚°ì´ í•„ìš”í•œ ê²½ìš° (ë°ì´í„°ì— ì§ì ‘ ì—†ìŒ):**
| ì‚¬ìš©ì í‘œí˜„ | í•„ìš”í•œ ê³„ì‚° | í™•ì‹ ë„ |
|------------|------------|--------|
| "ì¦ê°€ë¥ ", "ì¦ê°€ìœ¨", "ì„±ì¥ë¥ " | (ì¦ê°ëŸ‰/ì´ì „ê°’)*100 | REQUIRES_CALCULATION |
| "ê°ì†Œë¥ " | ê³„ì‚° í•„ìš” | REQUIRES_CALCULATION |

**ë§¤í•‘ ë¶ˆê°€ëŠ¥í•œ ê²½ìš°:**
- ì»¬ëŸ¼ì„ íŠ¹ì •í•  ìˆ˜ ì—†ëŠ” ëª¨í˜¸í•œ í‘œí˜„
- ë°ì´í„°ì— ì—†ëŠ” í•­ëª© ìš”ì²­

### Step 3: í™•ì‹ ë„ íŒì •
- HIGH: ëª…í™•í•˜ê²Œ ì»¬ëŸ¼ ë§¤í•‘ ê°€ëŠ¥
- MEDIUM: ìœ ì‚¬í•œ ì»¬ëŸ¼ì´ ìˆì§€ë§Œ í™•ì¸ í•„ìš”
- LOW: ëª¨í˜¸í•˜ì—¬ ì‚¬ìš©ì í™•ì¸ í•„ìš”
- REQUIRES_CALCULATION: ê³„ì‚°ì´ í•„ìš”í•œ íŒŒìƒ ì§€í‘œ
- NOT_FOUND: í•´ë‹¹ ë°ì´í„° ì—†ìŒ

### Step 4: ìµœì¢… ê²°ì •
- í™•ì‹ ë„ê°€ HIGHë©´ â†’ ì°¨íŠ¸ ìƒì„± ì§„í–‰
- í™•ì‹ ë„ê°€ MEDIUMì´ë©´ â†’ ê°€ì¥ ìœ ì‚¬í•œ ì»¬ëŸ¼ìœ¼ë¡œ ì§„í–‰í•˜ë˜ ì„¤ëª… ì¶”ê°€
- í™•ì‹ ë„ê°€ LOW/NOT_FOUNDë©´ â†’ ì‚¬ìš©ìì—ê²Œ ëª…í™•í™” ìš”ì²­
- REQUIRES_CALCULATIONì´ë©´ â†’ ê³„ì‚° ë¡œì§ ì ìš© ë˜ëŠ” ëŒ€ì•ˆ ì œì‹œ

---
## ì¶œë ¥ í˜•ì‹

```json
{{
    "reasoning": {{
        "step1_extraction": {{
            "target": "ëŒ€ìƒ (ì˜ˆ: ì™„ì†ì¶©ì „ê¸°)",
            "metric": "ì¸¡ì •ê°’ (ì˜ˆ: ì¦ê°€ë¥ )",
            "conditions": "ì¡°ê±´ (ì˜ˆ: 2025-10, top 3)",
            "visualization": "ì‹œê°í™” íƒ€ì…"
        }},
        "step2_column_mapping": {{
            "user_expression": "ì‚¬ìš©ìê°€ ì‚¬ìš©í•œ í‘œí˜„",
            "mapped_column": "ë§¤í•‘ëœ ì»¬ëŸ¼ëª… ë˜ëŠ” null",
            "mapping_reason": "ë§¤í•‘ ì´ìœ  ì„¤ëª…"
        }},
        "step3_confidence": {{
            "level": "HIGH | MEDIUM | LOW | REQUIRES_CALCULATION | NOT_FOUND",
            "reason": "í™•ì‹ ë„ íŒì • ì´ìœ "
        }},
        "step4_decision": {{
            "action": "PROCEED | CLARIFY | CALCULATE",
            "explanation": "ê²°ì • ì„¤ëª…"
        }}
    }},
    "needs_chart": true | false,
    "show_table": true | false,
    "output_format": "chart | table | text_only",
    "needs_clarification": true | false,
    "clarification_message": "ì‚¬ìš©ìì—ê²Œ ìš”ì²­í•  ëª…í™•í™” ë©”ì‹œì§€ (needs_clarificationì´ trueì¼ ë•Œ)",
    "chart_type": "line | bar | pie | area | none",
    "chart_title": "ì°¨íŠ¸/í‘œ ì œëª©",
    "data_filter": {{
        "cpo_name": null,
        "start_month": "YYYY-MM",
        "end_month": "YYYY-MM",
        "sort_column": "ì •ë ¬ ê¸°ì¤€ ì»¬ëŸ¼",
        "display_column": "í‘œì‹œí•  ê°’ ì»¬ëŸ¼",
        "limit": ìˆ«ì,
        "sort_order": "desc | asc",
        "include_others": true | false,
        "others_label": "ê¸°íƒ€ ë˜ëŠ” ì‚¬ìš©ìê°€ ì§€ì •í•œ ë¼ë²¨ (ì˜ˆ: others, ë‚˜ë¨¸ì§€ ë“±)"
    }},

## ğŸš¨ ë§¤ìš° ì¤‘ìš”: include_others ê·œì¹™ (ê¸°íƒ€ í•­ëª© í¬í•¨ ì—¬ë¶€)

### include_others: trueë¡œ ì„¤ì •í•˜ëŠ” ê²½ìš° (ëª…ì‹œì  ìš”ì²­ í•„ìˆ˜!)
ë‹¤ìŒ í‚¤ì›Œë“œê°€ **ëª…ì‹œì ìœ¼ë¡œ** í¬í•¨ëœ ê²½ìš°ì—ë§Œ trueë¡œ ì„¤ì •í•©ë‹ˆë‹¤:
- "ê¸°íƒ€", "ë‚˜ë¨¸ì§€", "others", "ê·¸ ì™¸", "ì™¸ ë‚˜ë¨¸ì§€", "í¬í•¨í•´ì„œ", "í•©ì³ì„œ"
- ì˜ˆ: "top 5ì™€ ê¸°íƒ€", "ë‚˜ë¨¸ì§€ëŠ” othersë¡œ", "ê¸°íƒ€ í¬í•¨", "ë‚˜ë¨¸ì§€ í•©ì³ì„œ"

### include_others: falseë¡œ ì„¤ì •í•˜ëŠ” ê²½ìš° (ê¸°ë³¸ê°’!)
- ìœ„ í‚¤ì›Œë“œê°€ **ì „í˜€ ì—†ëŠ”** ê²½ìš° â†’ ê¸°ë³¸ê°’ false
- "top 5ë¥¼ ì›í˜•ê·¸ë˜í”„ë¡œ" â†’ include_others: false (ê¸°íƒ€ ì–¸ê¸‰ ì—†ìŒ)
- "ì‹œì¥ì ìœ ìœ¨ ìƒìœ„ 3ê°œ" â†’ include_others: false (ê¸°íƒ€ ì–¸ê¸‰ ì—†ìŒ)

âš ï¸ ì£¼ì˜: ì›í˜•ê·¸ë˜í”„(íŒŒì´ì°¨íŠ¸)ë¼ê³  í•´ì„œ ìë™ìœ¼ë¡œ ê¸°íƒ€ë¥¼ í¬í•¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤!
ì‚¬ìš©ìê°€ ëª…ì‹œì ìœ¼ë¡œ "ê¸°íƒ€", "ë‚˜ë¨¸ì§€" ë“±ì„ ìš”ì²­í•œ ê²½ìš°ì—ë§Œ include_others: trueë¡œ ì„¤ì •í•˜ì„¸ìš”.
    "chart_config": {{
        "x_axis": "CPOëª…",
        "y_axis": "í‘œì‹œí•  ë°ì´í„°ëª…",
        "y_axis_type": "value | percentage | calculated_rate",
        "y_axis_label": "yì¶• ë¼ë²¨"
    }},
    "analysis_type": "ranking | trend | comparison",
    "calculation_required": {{
        "needed": true | false,
        "type": "growth_rate | null",
        "base_column": "ê¸°ì¤€ ì»¬ëŸ¼",
        "change_column": "ë³€í™”ëŸ‰ ì»¬ëŸ¼"
    }}
}}
```

## ì˜ˆì‹œ

### ì˜ˆì‹œ 1: "ì™„ì†ì¶©ì „ê¸° ì¦ê°€ëŸ‰ top 5" (í‘œ í˜•ì‹ - ì‹œê°í™” í‚¤ì›Œë“œ ì—†ìŒ)
```json
{{
    "reasoning": {{
        "step1_extraction": {{"output_format": "table"}},
        "step2_column_mapping": {{"mapped_column": "ì™„ì†ì¦ê°"}}
    }},
    "needs_chart": false,
    "show_table": true,
    "output_format": "table",
    "chart_type": "none",
    "data_filter": {{"sort_column": "ì™„ì†ì¦ê°", "display_column": "ì™„ì†ì¦ê°", "limit": 5}}
}}
```

### ì˜ˆì‹œ 2: "ì™„ì†ì¶©ì „ê¸° ì¦ê°€ëŸ‰ top 5 ë§‰ëŒ€ê·¸ë˜í”„ë¡œ ê·¸ë ¤ì¤˜" (ì°¨íŠ¸ í•„ìš”)
```json
{{
    "reasoning": {{
        "step1_extraction": {{"output_format": "chart"}}
    }},
    "needs_chart": true,
    "show_table": true,
    "output_format": "chart",
    "chart_type": "bar",
    "data_filter": {{"sort_column": "ì™„ì†ì¦ê°", "display_column": "ì™„ì†ì¦ê°", "limit": 5}}
}}
```

### ì˜ˆì‹œ 3: "ì™„ì†ì¶©ì „ê¸° ì¦ê°€ë¥  top 3ë¥¼ í‘œë¡œ ë³´ì—¬ì¤˜" (í‘œ í˜•ì‹ + ê³„ì‚° í•„ìš”)
```json
{{
    "reasoning": {{
        "step1_extraction": {{"output_format": "table"}},
        "step3_confidence": {{"level": "REQUIRES_CALCULATION"}}
    }},
    "needs_chart": false,
    "show_table": true,
    "output_format": "table",
    "chart_type": "none",
    "calculation_required": {{"needed": true, "type": "growth_rate", "base_column": "ì™„ì†ì¶©ì „ê¸°", "change_column": "ì™„ì†ì¦ê°"}}
}}
```

### ì˜ˆì‹œ 4: "ì™„ì†ì¶©ì „ê¸° ì¦ê°€ë¥  top 3 ê°„ë‹¨íˆ ì•Œë ¤ì¤˜" (í…ìŠ¤íŠ¸ë§Œ)
```json
{{
    "needs_chart": false,
    "show_table": false,
    "output_format": "text_only"
}}
```

### ì˜ˆì‹œ 5: "ì›í˜• í‘œë¡œ ë³´ì—¬ì¤˜" (í‘œ í˜•ì‹! ì°¨íŠ¸ ì•„ë‹˜!)
```json
{{
    "reasoning": {{"step1_extraction": {{"output_format": "table", "note": "ì›í˜• í‘œëŠ” ì°¨íŠ¸ê°€ ì•„ë‹Œ í…Œì´ë¸” í˜•ì‹"}}}},
    "needs_chart": false,
    "show_table": true,
    "output_format": "table",
    "chart_type": "none"
}}
```

### ì˜ˆì‹œ 6: "2025ë…„ 1ì›”ë¶€í„° 10ì›”ê¹Œì§€ ì „ì²´ CPO ê°œìˆ˜ ë³€í™”ë¥¼ ì•Œë ¤ì¤˜" (ì—‘ì…€ L3 ë°ì´í„°)
```json
{{
    "reasoning": {{
        "step1_extraction": {{
            "target": "CPO ê°œìˆ˜ (ì¶©ì „ì‚¬ì—…ì ìˆ˜)",
            "metric": "ê°œìˆ˜ ë³€í™”",
            "conditions": "2025-01~2025-10, ì „ì²´ CPO (ì—‘ì…€ L3)",
            "cpo_scope": "ì „ì²´ CPO = ì—‘ì…€ ìš”ì•½ í–‰ L3 ë°ì´í„°"
        }},
        "step2_column_mapping": {{
            "user_expression": "ì „ì²´ CPO ê°œìˆ˜",
            "mapped_column": "total_cpos",
            "mapping_reason": "ì „ì²´ CPO ê°œìˆ˜ëŠ” ì—‘ì…€ L3 ì…€ ê°’ (total_cpos)"
        }}
    }},
    "needs_chart": false,
    "show_table": true,
    "output_format": "table",
    "chart_type": "none",
    "analysis_type": "trend",
    "data_filter": {{
        "cpo_name": "ì „ì²´",
        "start_month": "2025-01",
        "end_month": "2025-10",
        "sort_column": "snapshot_month",
        "display_column": "total_cpos",
        "sort_order": "asc"
    }}
}}
```

### ì˜ˆì‹œ 7: "ì „ì²´ CPOì˜ ì™„ì†ì¶©ì „ê¸° ë‹¹ì›” ì¦ê°ëŸ‰ì„ ê·¸ë˜í”„ë¡œ ê·¸ë ¤ì¤˜" (ì—‘ì…€ N4 ë°ì´í„°)
```json
{{
    "reasoning": {{
        "step1_extraction": {{
            "target": "ì™„ì†ì¶©ì „ê¸°",
            "metric": "ë‹¹ì›” ì¦ê°ëŸ‰",
            "conditions": "ì „ì²´ CPO (ì—‘ì…€ N4)",
            "output_format": "chart"
        }},
        "step2_column_mapping": {{
            "user_expression": "ì „ì²´ ì™„ì†ì¶©ì „ê¸° ì¦ê°ëŸ‰",
            "mapped_column": "change_slow_chargers",
            "mapping_reason": "ì „ì²´ ì™„ì†ì¶©ì „ê¸° ë‹¹ì›” ì¦ê°ëŸ‰ì€ ì—‘ì…€ N4 ì…€ ê°’"
        }}
    }},
    "needs_chart": true,
    "show_table": true,
    "output_format": "chart",
    "chart_type": "line",
    "analysis_type": "trend",
    "data_filter": {{
        "cpo_name": "ì „ì²´",
        "display_column": "change_slow_chargers"
    }}
}}
```

### ì˜ˆì‹œ 8: "ì „ì²´ ì¶©ì „ì‚¬ì—…ìì˜ ê¸‰ì†ì¶©ì „ê¸° ê°œìˆ˜ë¥¼ ì•Œë ¤ì¤˜" (ì—‘ì…€ O3 ë°ì´í„°)
```json
{{
    "reasoning": {{
        "step1_extraction": {{
            "target": "ê¸‰ì†ì¶©ì „ê¸°",
            "metric": "ê°œìˆ˜",
            "conditions": "ì „ì²´ ì¶©ì „ì‚¬ì—…ì (ì—‘ì…€ O3)"
        }},
        "step2_column_mapping": {{
            "mapped_column": "total_fast_chargers"
        }}
    }},
    "needs_chart": false,
    "show_table": true,
    "output_format": "table",
    "data_filter": {{
        "cpo_name": "ì „ì²´",
        "display_column": "total_fast_chargers"
    }}
}}
```

### ì˜ˆì‹œ 9: "ì‹œì¥ì ìœ ìœ¨ top 5ë¥¼ ì›í˜•ê·¸ë˜í”„ë¡œ ê·¸ë ¤ì¤˜" (ê¸°íƒ€ í•­ëª© ì—†ìŒ - ê¸°ë³¸ê°’!)
```json
{{
    "reasoning": {{
        "step1_extraction": {{
            "target": "CPO",
            "metric": "ì‹œì¥ì ìœ ìœ¨",
            "conditions": "top 5, ê¸°íƒ€ ì–¸ê¸‰ ì—†ìŒ",
            "output_format": "chart"
        }}
    }},
    "needs_chart": true,
    "show_table": true,
    "output_format": "chart",
    "chart_type": "pie",
    "chart_title": "ì‹œì¥ì ìœ ìœ¨ Top 5 CPO",
    "analysis_type": "ranking",
    "data_filter": {{
        "sort_column": "ì‹œì¥ì ìœ ìœ¨",
        "display_column": "ì‹œì¥ì ìœ ìœ¨",
        "limit": 5,
        "sort_order": "desc",
        "include_others": false
    }},
    "chart_config": {{
        "x_axis": "CPOëª…",
        "y_axis": "ì‹œì¥ì ìœ ìœ¨",
        "y_axis_type": "percentage",
        "y_axis_label": "ì‹œì¥ì ìœ ìœ¨ (%)"
    }}
}}
```

### ì˜ˆì‹œ 10: "ì‹œì¥ì ìœ ìœ¨ top 5ë¥¼ ì›í˜•ê·¸ë˜í”„ë¡œ ê·¸ë ¤ì¤˜, othersë¡œ ë‚˜ë¨¸ì§€ í‘œì‹œ" (ê¸°íƒ€ í•­ëª© + ì˜ì–´ ë¼ë²¨)
```json
{{
    "reasoning": {{
        "step1_extraction": {{
            "target": "CPO",
            "metric": "ì‹œì¥ì ìœ ìœ¨",
            "conditions": "top 5, ë‚˜ë¨¸ì§€ëŠ” othersë¡œ í‘œì‹œ",
            "output_format": "chart"
        }}
    }},
    "needs_chart": true,
    "show_table": true,
    "output_format": "chart",
    "chart_type": "pie",
    "chart_title": "ì‹œì¥ì ìœ ìœ¨ Top 5 + Others",
    "analysis_type": "ranking",
    "data_filter": {{
        "sort_column": "ì‹œì¥ì ìœ ìœ¨",
        "display_column": "ì‹œì¥ì ìœ ìœ¨",
        "limit": 5,
        "sort_order": "desc",
        "include_others": true,
        "others_label": "others"
    }},
    "chart_config": {{
        "x_axis": "CPOëª…",
        "y_axis": "ì‹œì¥ì ìœ ìœ¨",
        "y_axis_type": "percentage",
        "y_axis_label": "ì‹œì¥ì ìœ ìœ¨ (%)"
    }}
}}
```

### ì˜ˆì‹œ 11: "ì‹œì¥ì ìœ ìœ¨ top 3ë¥¼ íŒŒì´ì°¨íŠ¸ë¡œ, ê¸°íƒ€ í¬í•¨" (ê¸°íƒ€ í•­ëª© + í•œêµ­ì–´ ê¸°ë³¸ê°’)
```json
{{
    "reasoning": {{
        "step1_extraction": {{
            "target": "CPO",
            "metric": "ì‹œì¥ì ìœ ìœ¨",
            "conditions": "top 3, ê¸°íƒ€ í¬í•¨",
            "output_format": "chart"
        }}
    }},
    "needs_chart": true,
    "show_table": true,
    "output_format": "chart",
    "chart_type": "pie",
    "chart_title": "ì‹œì¥ì ìœ ìœ¨ Top 3 + ê¸°íƒ€",
    "analysis_type": "ranking",
    "data_filter": {{
        "sort_column": "ì‹œì¥ì ìœ ìœ¨",
        "display_column": "ì‹œì¥ì ìœ ìœ¨",
        "limit": 3,
        "sort_order": "desc",
        "include_others": true,
        "others_label": "ê¸°íƒ€"
    }},
    "chart_config": {{
        "x_axis": "CPOëª…",
        "y_axis": "ì‹œì¥ì ìœ ìœ¨",
        "y_axis_type": "percentage",
        "y_axis_label": "ì‹œì¥ì ìœ ìœ¨ (%)"
    }}
}}
```

JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”.
"""
        
        try:
            payload = {
                'anthropic_version': Config.ANTHROPIC_VERSION,
                'max_tokens': 2048,  # Chain of Thought ì‘ë‹µì„ ìœ„í•´ ì¦ê°€
                'temperature': 0.1,
                'messages': [{'role': 'user', 'content': analysis_prompt}]
            }
            
            response = self.bedrock_client.invoke_model(
                modelId=Config.MODEL_ID,
                contentType='application/json',
                accept='application/json',
                body=json.dumps(payload)
            )
            
            response_body = json.loads(response['body'].read())
            result_text = response_body['content'][0]['text']
            
            # JSON ì¶”ì¶œ
            json_match = re.search(r'\{[\s\S]*\}', result_text)
            if json_match:
                return json.loads(json_match.group())
            
            return {'needs_chart': False, 'analysis_type': 'single'}
            
        except Exception as e:
            print(f'âŒ ì§ˆì˜ ë¶„ì„ ì˜¤ë¥˜: {e}')
            return {'needs_chart': False, 'analysis_type': 'single'}
    
    def _calculate_y_values(self, top_df, col, y_axis_type, full_df, calculation_info=None):
        """yì¶• ê°’ ê³„ì‚° (ì ˆëŒ€ê°’, ì ìœ ìœ¨, ë˜ëŠ” ì¦ê°€ë¥ )"""
        
        def to_python_type(val):
            """numpy íƒ€ì…ì„ Python ê¸°ë³¸ íƒ€ì…ìœ¼ë¡œ ë³€í™˜"""
            import numpy as np
            if isinstance(val, (np.integer, np.int64, np.int32)):
                return int(val)
            elif isinstance(val, (np.floating, np.float64, np.float32)):
                return float(val)
            return val
        
        # ì¦ê°€ë¥  ê³„ì‚°ì´ í•„ìš”í•œ ê²½ìš°
        if y_axis_type == 'calculated_rate' and calculation_info:
            calc_type = calculation_info.get('type')
            base_col = calculation_info.get('base_column')
            change_col = calculation_info.get('change_column')
            
            if calc_type == 'growth_rate' and base_col in top_df.columns and change_col in top_df.columns:
                # ì¦ê°€ë¥  = (ì¦ê°ëŸ‰ / (í˜„ì¬ê°’ - ì¦ê°ëŸ‰)) * 100
                # í˜„ì¬ê°’ - ì¦ê°ëŸ‰ = ì´ì „ ì›” ê°’
                values = []
                for idx, row in top_df.iterrows():
                    current_val = row[base_col]
                    change_val = row[change_col]
                    prev_val = current_val - change_val
                    
                    if prev_val > 0:
                        rate = (change_val / prev_val) * 100
                        values.append(round(float(rate), 2))
                    else:
                        # ì´ì „ ê°’ì´ 0ì´ë©´ ì¦ê°€ë¥  ê³„ì‚° ë¶ˆê°€ (ë¬´í•œëŒ€ ë°©ì§€)
                        values.append(0.0 if change_val == 0 else 100.0)
                
                print(f'      â”œâ”€ ì¦ê°€ë¥  ê³„ì‚°: {change_col}/{base_col}-{change_col}*100', flush=True)
                return values
        
        # ì ìœ ìœ¨ ê³„ì‚°
        if y_axis_type == 'percentage':
            total = full_df[col].sum()
            if total > 0:
                values = [(to_python_type(v) / float(total) * 100) for v in top_df[col].tolist()]
                print(f'      â”œâ”€ ì ìœ ìœ¨ ê³„ì‚°: ì „ì²´ í•©ê³„ {total:,}, ì ìœ ìœ¨ë¡œ ë³€í™˜', flush=True)
                return [round(v, 2) for v in values]
            return [to_python_type(v) for v in top_df[col].tolist()]
        
        # ì ˆëŒ€ê°’ ê·¸ëŒ€ë¡œ ë°˜í™˜ (numpy íƒ€ì… ë³€í™˜)
        return [to_python_type(v) for v in top_df[col].tolist()]
    
    def _validate_column_exists(self, col: str, df) -> tuple:
        """ì»¬ëŸ¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸ ë° ìœ ì‚¬ ì»¬ëŸ¼ ì¶”ì²œ"""
        if col in df.columns:
            return True, col, None
        
        # ìœ ì‚¬ ì»¬ëŸ¼ ì°¾ê¸°
        similar_cols = []
        col_lower = col.lower()
        for c in df.columns:
            c_lower = c.lower()
            # ë¶€ë¶„ ë¬¸ìì—´ ë§¤ì¹­
            if col_lower in c_lower or c_lower in col_lower:
                similar_cols.append(c)
            # í‚¤ì›Œë“œ ë§¤ì¹­
            keywords = ['ì¶©ì „', 'ì¦ê°', 'ì ìœ ', 'ìˆœìœ„']
            for kw in keywords:
                if kw in col_lower and kw in c_lower:
                    if c not in similar_cols:
                        similar_cols.append(c)
        
        return False, None, similar_cols
    
    def extract_chart_data(self, df, intent: dict) -> dict:
        """DataFrameì—ì„œ ì°¨íŠ¸ ë°ì´í„° ì¶”ì¶œ (Text-to-SQL ë°©ì‹)"""
        try:
            import numpy as np
            
            # numpy íƒ€ì…ì„ Python ê¸°ë³¸ íƒ€ì…ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” í—¬í¼ í•¨ìˆ˜
            def to_python_type(val):
                if isinstance(val, (np.integer, np.int64, np.int32)):
                    return int(val)
                elif isinstance(val, (np.floating, np.float64, np.float32)):
                    return float(val)
                return val
            
            def convert_values_list(values):
                """ë¦¬ìŠ¤íŠ¸ ë‚´ ëª¨ë“  ê°’ì„ Python ê¸°ë³¸ íƒ€ì…ìœ¼ë¡œ ë³€í™˜"""
                return [to_python_type(v) for v in values]
            
            data_filter = intent.get('data_filter', {})
            chart_config = intent.get('chart_config', {})
            
            cpo_name = data_filter.get('cpo_name')
            start_month = data_filter.get('start_month')
            end_month = data_filter.get('end_month')
            
            # Text-to-SQL: sort_columnê³¼ display_column ë¶„ë¦¬
            sort_column = data_filter.get('sort_column')  # ORDER BY ì»¬ëŸ¼
            display_column = data_filter.get('display_column')  # SELECT ì»¬ëŸ¼ (yì¶• ê°’)
            column = data_filter.get('column', 'ì´ì¶©ì „ê¸°')  # ê¸°ì¡´ í˜¸í™˜ì„±
            
            # sort_columnì´ ì—†ìœ¼ë©´ column ì‚¬ìš© (ê¸°ì¡´ í˜¸í™˜ì„±)
            if not sort_column:
                sort_column = column
            if not display_column:
                display_column = column
            
            limit = data_filter.get('limit')
            sort_order = data_filter.get('sort_order', 'desc')
            
            # ì°¨íŠ¸ ì¶• ì„¤ì •
            y_axis_type = chart_config.get('y_axis_type', 'value')
            y_axis_label = chart_config.get('y_axis_label', 'ê°’')
            x_axis = chart_config.get('x_axis', 'CPOëª…')
            
            # limitì´ Noneì´ë©´ ê¸°ë³¸ê°’ 10, ëª…ì‹œë˜ë©´ í•´ë‹¹ ê°’ ì‚¬ìš©
            result_limit = limit if limit is not None else 10
            
            print(f'      â”œâ”€ ì •ë ¬ ì»¬ëŸ¼ (ORDER BY): {sort_column}', flush=True)
            print(f'      â”œâ”€ í‘œì‹œ ì»¬ëŸ¼ (SELECT): {display_column}', flush=True)
            print(f'      â”œâ”€ ê°œìˆ˜ ì œí•œ (LIMIT): {limit} â†’ ì ìš©ê°’: {result_limit}', flush=True)
            print(f'      â”œâ”€ ì •ë ¬ ìˆœì„œ: {sort_order}', flush=True)
            print(f'      â”œâ”€ Yì¶• íƒ€ì…: {y_axis_type} ({y_axis_label})', flush=True)
            print(f'      â””â”€ Xì¶•: {x_axis}', flush=True)
            
            # ì»¬ëŸ¼ëª… ì •ê·œí™” í•¨ìˆ˜
            def normalize_column(col):
                if col is None:
                    return 'ì´ì¶©ì „ê¸°'
                col_str = str(col)
                
                # ì˜ì–´ ì»¬ëŸ¼ëª… â†’ í•œêµ­ì–´ DataFrame ì»¬ëŸ¼ëª… ë§¤í•‘ (ì—‘ì…€ ìš”ì•½ í–‰ ì»¬ëŸ¼)
                english_to_korean_col = {
                    # ì „ì²´ í˜„í™© (L3:P3) - DataFrame ì»¬ëŸ¼ëª…ìœ¼ë¡œ ë³€í™˜
                    'total_cpos': 'total_cpos',  # ì—‘ì…€ ì „ìš© (DataFrameì— ì—†ìŒ)
                    'total_stations': 'ì¶©ì „ì†Œìˆ˜',
                    'total_slow_chargers': 'ì™„ì†ì¶©ì „ê¸°',
                    'total_fast_chargers': 'ê¸‰ì†ì¶©ì „ê¸°',
                    'total_chargers': 'ì´ì¶©ì „ê¸°',
                    # ë‹¹ì›” ì¦ê°ëŸ‰ (L4:P4) - DataFrame ì»¬ëŸ¼ëª…ìœ¼ë¡œ ë³€í™˜
                    'change_cpos': 'change_cpos',  # ì—‘ì…€ ì „ìš© (DataFrameì— ì—†ìŒ)
                    'change_stations': 'ì¶©ì „ì†Œì¦ê°',
                    'change_slow_chargers': 'ì™„ì†ì¦ê°',
                    'change_fast_chargers': 'ê¸‰ì†ì¦ê°',
                    'change_total_chargers': 'ì´ì¦ê°',
                }
                
                # ì˜ì–´ ì»¬ëŸ¼ëª…ì´ë©´ í•œêµ­ì–´ë¡œ ë³€í™˜
                if col_str in english_to_korean_col:
                    return english_to_korean_col[col_str]
                
                # ì •í™•í•œ ë§¤ì¹­ ìš°ì„  (ë” êµ¬ì²´ì ì¸ í‚¤ë¥¼ ë¨¼ì € ì²´í¬)
                exact_mapping = {
                    'ì™„ì†ì¦ê°': 'ì™„ì†ì¦ê°',
                    'ê¸‰ì†ì¦ê°': 'ê¸‰ì†ì¦ê°',
                    'ì´ì¦ê°': 'ì´ì¦ê°',
                    'ì¶©ì „ì†Œì¦ê°': 'ì¶©ì „ì†Œì¦ê°',
                    'ì™„ì†ì¶©ì „ê¸°': 'ì™„ì†ì¶©ì „ê¸°',
                    'ê¸‰ì†ì¶©ì „ê¸°': 'ê¸‰ì†ì¶©ì „ê¸°',
                    'ì´ì¶©ì „ê¸°': 'ì´ì¶©ì „ê¸°',
                    'ì¶©ì „ì†Œìˆ˜': 'ì¶©ì „ì†Œìˆ˜',
                    'ì‹œì¥ì ìœ ìœ¨': 'ì‹œì¥ì ìœ ìœ¨'
                }
                
                # ì •í™•íˆ ì¼ì¹˜í•˜ë©´ ë°”ë¡œ ë°˜í™˜
                if col_str in exact_mapping:
                    return exact_mapping[col_str]
                
                # ë¶€ë¶„ ë§¤ì¹­ (ì¦ê° í‚¤ì›Œë“œ ë¨¼ì € ì²´í¬ - ìˆœì„œ ì¤‘ìš”!)
                partial_mapping = [
                    ('ì™„ì†ì¦ê°', 'ì™„ì†ì¦ê°'),
                    ('ê¸‰ì†ì¦ê°', 'ê¸‰ì†ì¦ê°'),
                    ('ì´ì¦ê°', 'ì´ì¦ê°'),
                    ('ì¶©ì „ì†Œì¦ê°', 'ì¶©ì „ì†Œì¦ê°'),
                    ('ì™„ì†', 'ì™„ì†ì¶©ì „ê¸°'),
                    ('ê¸‰ì†', 'ê¸‰ì†ì¶©ì „ê¸°'),
                    ('ì´', 'ì´ì¶©ì „ê¸°'),
                    ('ì¶©ì „ì†Œ', 'ì¶©ì „ì†Œìˆ˜'),
                    ('ì ìœ ìœ¨', 'ì‹œì¥ì ìœ ìœ¨')
                ]
                
                for key, val in partial_mapping:
                    if key in col_str:
                        return val
                return col
            
            # ì‹œì¥ì ìœ ìœ¨ ê°’ ë³€í™˜ í•¨ìˆ˜ (ì†Œìˆ˜ì  â†’ í¼ì„¼íŠ¸) + numpy íƒ€ì… ë³€í™˜
            def convert_market_share(col_name, values):
                """ì‹œì¥ì ìœ ìœ¨ ì»¬ëŸ¼ì¸ ê²½ìš° ì†Œìˆ˜ì ì„ í¼ì„¼íŠ¸ë¡œ ë³€í™˜í•˜ê³  numpy íƒ€ì…ì„ Python íƒ€ì…ìœ¼ë¡œ ë³€í™˜"""
                converted = []
                for v in values:
                    # numpy íƒ€ì…ì„ Python íƒ€ì…ìœ¼ë¡œ ë³€í™˜
                    v = to_python_type(v)
                    if col_name == 'ì‹œì¥ì ìœ ìœ¨' and v is not None and v < 1:
                        # ê°’ì´ 1 ë¯¸ë§Œì´ë©´ ì†Œìˆ˜ì  í˜•íƒœì´ë¯€ë¡œ 100ì„ ê³±í•´ í¼ì„¼íŠ¸ë¡œ ë³€í™˜
                        converted.append(round(float(v) * 100, 2))
                    else:
                        converted.append(v)
                return converted
            
            # ì˜ì–´ ì»¬ëŸ¼ëª… â†’ í•œêµ­ì–´ ë¼ë²¨ ë³€í™˜ í•¨ìˆ˜
            def to_korean_label(col_name):
                """ì˜ì–´ ì»¬ëŸ¼ëª…ì„ í•œêµ­ì–´ ë¼ë²¨ë¡œ ë³€í™˜"""
                korean_mapping = {
                    # ì „ì²´ í˜„í™© (L3:P3)
                    'total_cpos': 'CPO ê°œìˆ˜',
                    'total_stations': 'ì¶©ì „ì†Œ ê°œìˆ˜',
                    'total_slow_chargers': 'ì™„ì†ì¶©ì „ê¸° ê°œìˆ˜',
                    'total_fast_chargers': 'ê¸‰ì†ì¶©ì „ê¸° ê°œìˆ˜',
                    'total_chargers': 'ì „ì²´ì¶©ì „ê¸° ê°œìˆ˜',
                    # ë‹¹ì›” ì¦ê°ëŸ‰ (L4:P4)
                    'change_cpos': 'CPO ì¦ê°ëŸ‰',
                    'change_stations': 'ì¶©ì „ì†Œ ì¦ê°ëŸ‰',
                    'change_slow_chargers': 'ì™„ì†ì¶©ì „ê¸° ì¦ê°ëŸ‰',
                    'change_fast_chargers': 'ê¸‰ì†ì¶©ì „ê¸° ì¦ê°ëŸ‰',
                    'change_total_chargers': 'ì „ì²´ì¶©ì „ê¸° ì¦ê°ëŸ‰',
                    # ê¸°ì¡´ í•œêµ­ì–´ ì»¬ëŸ¼ëª… (ê·¸ëŒ€ë¡œ ìœ ì§€)
                    'ì™„ì†ì¦ê°': 'ì™„ì†ì¶©ì „ê¸° ì¦ê°ëŸ‰',
                    'ê¸‰ì†ì¦ê°': 'ê¸‰ì†ì¶©ì „ê¸° ì¦ê°ëŸ‰',
                    'ì´ì¦ê°': 'ì „ì²´ì¶©ì „ê¸° ì¦ê°ëŸ‰',
                    'ì¶©ì „ì†Œì¦ê°': 'ì¶©ì „ì†Œ ì¦ê°ëŸ‰',
                    'ì™„ì†ì¶©ì „ê¸°': 'ì™„ì†ì¶©ì „ê¸° ê°œìˆ˜',
                    'ê¸‰ì†ì¶©ì „ê¸°': 'ê¸‰ì†ì¶©ì „ê¸° ê°œìˆ˜',
                    'ì´ì¶©ì „ê¸°': 'ì „ì²´ì¶©ì „ê¸° ê°œìˆ˜',
                    'ì¶©ì „ì†Œìˆ˜': 'ì¶©ì „ì†Œ ê°œìˆ˜',
                    'ì‹œì¥ì ìœ ìœ¨': 'ì‹œì¥ì ìœ ìœ¨',
                    'ìˆœìœ„': 'ìˆœìœ„',
                    'ìˆœìœ„ë³€ë™': 'ìˆœìœ„ ë³€ë™',
                }
                return korean_mapping.get(col_name, col_name)
            
            # ë‹¤ì¤‘ ì»¬ëŸ¼ ì§€ì› (ë¦¬ìŠ¤íŠ¸ ë˜ëŠ” ì‰¼í‘œ êµ¬ë¶„ ë¬¸ìì—´)
            columns = []
            
            # display_columnì´ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš°
            if isinstance(display_column, list):
                columns = [normalize_column(c) for c in display_column]
                print(f'      â”œâ”€ ğŸ”€ ë‹¤ì¤‘ ì»¬ëŸ¼ ê°ì§€ (ë¦¬ìŠ¤íŠ¸): {display_column} â†’ {columns}', flush=True)
            # display_columnì´ ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ë‹¤ì¤‘ ì»¬ëŸ¼ì¸ì§€ í™•ì¸
            elif display_column and ',' in str(display_column):
                # ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ë‹¤ì¤‘ ì»¬ëŸ¼ íŒŒì‹±
                multi_cols = [c.strip() for c in str(display_column).split(',')]
                columns = [normalize_column(c) for c in multi_cols]
                print(f'      â”œâ”€ ğŸ”€ ë‹¤ì¤‘ ì»¬ëŸ¼ ê°ì§€: {multi_cols} â†’ {columns}', flush=True)
            # display_columnì´ ë‹¨ì¼ ê°’ì¸ ê²½ìš° (ìˆ˜ì •: column ëŒ€ì‹  display_column ì‚¬ìš©)
            elif display_column:
                columns = [normalize_column(display_column)]
            elif isinstance(column, list):
                columns = [normalize_column(c) for c in column]
            else:
                columns = [normalize_column(column)]
            
            # ë°ì´í„° í•„í„°ë§
            filtered_df = df.copy()
            
            # CPO í•„í„° (ë‹¨ì¼ ë˜ëŠ” ë‹¤ì¤‘ CPO ì§€ì›)
            cpo_list = []
            has_total_cpo = False  # 'ì „ì²´' CPO ìš”ì²­ ì—¬ë¶€
            if cpo_name:
                if isinstance(cpo_name, list):
                    cpo_list = cpo_name
                else:
                    cpo_list = [cpo_name]
                # 'ì „ì²´' í‚¤ì›Œë“œ í™•ì¸
                total_keywords = ['ì „ì²´', 'ì „ì²´cpo', 'ì „ì²´ cpo', 'all', 'total']
                has_total_cpo = any(kw in [c.lower() for c in cpo_list] for kw in total_keywords)
                # 'ì „ì²´'ë¥¼ ì œì™¸í•œ ì‹¤ì œ CPO ëª©ë¡
                actual_cpo_list = [c for c in cpo_list if c.lower() not in total_keywords]
            else:
                actual_cpo_list = []
            
            if actual_cpo_list and 'CPOëª…' in filtered_df.columns:
                # ë‹¤ì¤‘ CPO í•„í„°ë§ (ì „ì²´ ì œì™¸) - ë„ì–´ì“°ê¸° ë¬´ì‹œ
                def normalize_cpo_name(name):
                    """CPOëª… ì •ê·œí™”: ë„ì–´ì“°ê¸° ì œê±°, ì†Œë¬¸ì ë³€í™˜"""
                    return str(name).replace(' ', '').replace('\u3000', '').lower()
                
                mask = filtered_df['CPOëª…'].apply(
                    lambda x: any(normalize_cpo_name(cpo) in normalize_cpo_name(x) for cpo in actual_cpo_list) if pd.notna(x) else False
                )
                filtered_df = filtered_df[mask]
                print(f'      â”œâ”€ CPO í•„í„° (ë‹¤ì¤‘): {actual_cpo_list}', flush=True)
            
            if has_total_cpo:
                print(f'      â”œâ”€ ğŸ“Š ì „ì²´ CPO í•©ê³„ ìš”ì²­ ê°ì§€', flush=True)
            
            # ê¸°ê°„ í•„í„°
            if 'snapshot_month' in filtered_df.columns:
                if start_month:
                    filtered_df = filtered_df[filtered_df['snapshot_month'] >= start_month]
                if end_month:
                    filtered_df = filtered_df[filtered_df['snapshot_month'] <= end_month]
            
            if len(filtered_df) == 0:
                return {'labels': [], 'values': [], 'error': 'í•´ë‹¹ ì¡°ê±´ì˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤'}
            
            # ì°¨íŠ¸ íƒ€ì…ì— ë”°ë¥¸ ë°ì´í„° êµ¬ì„±
            analysis_type = intent.get('analysis_type', 'trend')
            
            # ë‹¨ì¼ ì»¬ëŸ¼ (ë‹¤ì¤‘ ì»¬ëŸ¼ì€ ê° analysis_type ë‚´ë¶€ì—ì„œ ì²˜ë¦¬)
            col = columns[0]
            
            if analysis_type == 'trend':
                # ì‹œê°„ë³„ ì¶”ì´
                print(f'      â”œâ”€ Trend ë¶„ì„: ì»¬ëŸ¼ ìˆ˜={len(columns)}, ì»¬ëŸ¼={columns}', flush=True)
                print(f'      â”œâ”€ í•„í„°ë§ í›„ ë°ì´í„°: {len(filtered_df)}í–‰', flush=True)
                
                if cpo_name:
                    print(f'      â”œâ”€ CPO í•„í„°: {cpo_name}', flush=True)
                    unique_cpos = filtered_df['CPOëª…'].unique().tolist() if 'CPOëª…' in filtered_df.columns else []
                    print(f'      â”œâ”€ í•„í„°ë§ëœ CPO: {unique_cpos[:5]}...', flush=True)
                
                # ì „ì²´ CPO í•©ê³„ê°€ í•„ìš”í•œ ê²½ìš° (ì—‘ì…€ L3:P4 ë²”ìœ„)
                # "ì „ì²´", "ì „ì²´CPO", "ì „ì²´ CPO", "ì¶©ì „ì‚¬ì—…ì" ë“±ì˜ í‚¤ì›Œë“œ ê°ì§€
                def is_total_cpo_query(cpo_name_val):
                    if cpo_name_val is None:
                        return False
                    if isinstance(cpo_name_val, list):
                        return any(is_total_cpo_query(c) for c in cpo_name_val)
                    cpo_lower = str(cpo_name_val).lower().replace(' ', '')
                    total_keywords = ['ì „ì²´', 'ì „ì²´cpo', 'ì¶©ì „ì‚¬ì—…ì', 'total', 'all']
                    return any(kw in cpo_lower for kw in total_keywords)
                
                is_total_query = is_total_cpo_query(cpo_name)
                is_total_with_cpo_query = has_total_cpo and actual_cpo_list  # ì „ì²´ + íŠ¹ì • CPO ë¹„êµ ìš”ì²­
                
                # ì „ì²´ CPO ê´€ë ¨ ì»¬ëŸ¼ ë§¤í•‘ (ì—‘ì…€ ì…€ ìœ„ì¹˜ ê¸°ë°˜)
                total_column_mapping = {
                    # ì „ì²´ í˜„í™© (L3:P3)
                    'total_cpos': ('total', 'cpos'),           # L3
                    'total_stations': ('total', 'stations'),   # M3
                    'total_slow_chargers': ('total', 'slow_chargers'),  # N3
                    'total_fast_chargers': ('total', 'fast_chargers'),  # O3
                    'total_chargers': ('total', 'total_chargers'),      # P3
                    # ë‹¹ì›” ì¦ê°ëŸ‰ (L4:P4)
                    'change_cpos': ('change', 'cpos'),         # L4
                    'change_stations': ('change', 'stations'), # M4
                    'change_slow_chargers': ('change', 'slow_chargers'),  # N4
                    'change_fast_chargers': ('change', 'fast_chargers'),  # O4
                    'change_total_chargers': ('change', 'total_chargers'), # P4
                    # ê¸°ì¡´ ì»¬ëŸ¼ëª… í˜¸í™˜
                    'ì™„ì†ì¦ê°': ('change', 'slow_chargers'),
                    'ê¸‰ì†ì¦ê°': ('change', 'fast_chargers'),
                    'ì´ì¦ê°': ('change', 'total_chargers'),
                    'ì¶©ì „ì†Œì¦ê°': ('change', 'stations'),
                }
                
                # ì „ì²´ CPO ê´€ë ¨ ì»¬ëŸ¼ì¸ì§€ í™•ì¸
                is_total_column = any(c in total_column_mapping for c in columns)
                
                if is_total_query and is_total_column:
                    print(f'      â”œâ”€ ğŸ“Š ì „ì²´ CPO í•©ê³„ ì¡°íšŒ - ì—‘ì…€ ìš”ì•½ í–‰(L3:P4)ì—ì„œ ì§ì ‘ ì¶”ì¶œ', flush=True)
                    print(f'      â”œâ”€ ìš”ì²­ ì»¬ëŸ¼: {columns}', flush=True)
                    
                    # ì—‘ì…€ íŒŒì¼ì—ì„œ ì§ì ‘ í•©ê³„ ë°ì´í„° ì¶”ì¶œ
                    from data_loader import ChargingDataLoader
                    loader = ChargingDataLoader()
                    
                    # ì›”ë³„ í•©ê³„ ë°ì´í„° ìˆ˜ì§‘
                    monthly_totals = {}
                    files = loader.list_available_files()
                    
                    for file_info in files:
                        s3_key = file_info['key']
                        filename = file_info['filename']
                        _, snapshot_month = loader.parse_snapshot_date_from_filename(filename)
                        
                        if snapshot_month and (not start_month or snapshot_month >= start_month) and (not end_month or snapshot_month <= end_month):
                            summary = loader.extract_summary_data(s3_key)
                            if summary:
                                monthly_totals[snapshot_month] = {
                                    # ì „ì²´ í˜„í™© (L3:P3)
                                    'total_cpos': summary.get('total', {}).get('cpos', 0),
                                    'total_stations': summary.get('total', {}).get('stations', 0),
                                    'total_slow_chargers': summary.get('total', {}).get('slow_chargers', 0),
                                    'total_fast_chargers': summary.get('total', {}).get('fast_chargers', 0),
                                    'total_chargers': summary.get('total', {}).get('total_chargers', 0),
                                    # ë‹¹ì›” ì¦ê°ëŸ‰ (L4:P4)
                                    'change_cpos': summary.get('change', {}).get('cpos', 0),
                                    'change_stations': summary.get('change', {}).get('stations', 0),
                                    'change_slow_chargers': summary.get('change', {}).get('slow_chargers', 0),
                                    'change_fast_chargers': summary.get('change', {}).get('fast_chargers', 0),
                                    'change_total_chargers': summary.get('change', {}).get('total_chargers', 0),
                                    # ê¸°ì¡´ ì»¬ëŸ¼ëª… í˜¸í™˜
                                    'ì™„ì†ì¦ê°': summary.get('change', {}).get('slow_chargers', 0),
                                    'ê¸‰ì†ì¦ê°': summary.get('change', {}).get('fast_chargers', 0),
                                    'ì´ì¦ê°': summary.get('change', {}).get('total_chargers', 0),
                                    'ì¶©ì „ì†Œì¦ê°': summary.get('change', {}).get('stations', 0),
                                }
                                print(f'      â”œâ”€ {snapshot_month}: ì¶”ì¶œ ì™„ë£Œ', flush=True)
                    
                    if monthly_totals:
                        sorted_months = sorted(monthly_totals.keys())
                        
                        # ì „ì²´ CPO + íŠ¹ì • CPO ë¹„êµì¸ ê²½ìš°
                        if is_total_with_cpo_query and actual_cpo_list:
                            result = {'labels': sorted_months, 'series': [], 'multi_series': True}
                            
                            # 1. ì „ì²´ CPO ì‹œë¦¬ì¦ˆ ì¶”ê°€
                            for target_col in columns:
                                values = [monthly_totals.get(m, {}).get(target_col, 0) for m in sorted_months]
                                korean_label = to_korean_label(target_col)
                                result['series'].append({'name': f'ì „ì²´ {korean_label}', 'values': values})
                                print(f'      â”œâ”€ ì‹œë¦¬ì¦ˆ ì¶”ê°€ (ì „ì²´ CPO): ì „ì²´ {korean_label} = {values[:3]}...', flush=True)
                            
                            # 2. íŠ¹ì • CPO ì‹œë¦¬ì¦ˆ ì¶”ê°€
                            for cpo in actual_cpo_list:
                                # í•´ë‹¹ CPO ë°ì´í„° í•„í„°ë§
                                cpo_mask = df['CPOëª…'].apply(
                                    lambda x: cpo.lower() in str(x).lower() if pd.notna(x) else False
                                )
                                cpo_df = df[cpo_mask]
                                
                                # ê¸°ê°„ í•„í„°
                                if 'snapshot_month' in cpo_df.columns:
                                    if start_month:
                                        cpo_df = cpo_df[cpo_df['snapshot_month'] >= start_month]
                                    if end_month:
                                        cpo_df = cpo_df[cpo_df['snapshot_month'] <= end_month]
                                
                                for target_col in columns:
                                    if target_col in cpo_df.columns:
                                        grouped = cpo_df.groupby('snapshot_month')[target_col].first().reset_index()
                                        grouped = grouped.sort_values('snapshot_month')
                                        
                                        # sorted_monthsì— ë§ì¶° ê°’ ì •ë ¬
                                        values = []
                                        for m in sorted_months:
                                            month_val = grouped[grouped['snapshot_month'] == m][target_col].values
                                            values.append(float(month_val[0]) if len(month_val) > 0 else 0)
                                        
                                        korean_label = to_korean_label(target_col)
                                        result['series'].append({'name': f'{cpo} {korean_label}', 'values': values})
                                        print(f'      â”œâ”€ ì‹œë¦¬ì¦ˆ ì¶”ê°€ ({cpo}): {cpo} {korean_label} = {values[:3]}...', flush=True)
                            
                            result['y_axis_label'] = chart_config.get('y_axis_label', 'ê°’')
                            print(f'      â””â”€ ì „ì²´+CPO ë¹„êµ ì™„ë£Œ: {len(result["series"])}ê°œ ì‹œë¦¬ì¦ˆ', flush=True)
                            return result
                        
                        # ì „ì²´ CPOë§Œ ìš”ì²­í•œ ê²½ìš° (ê¸°ì¡´ ë¡œì§)
                        # ë‹¤ì¤‘ ì»¬ëŸ¼ì¸ ê²½ìš°
                        if len(columns) > 1:
                            result = {'labels': sorted_months, 'series': [], 'multi_series': True}
                            for target_col in columns:
                                values = [monthly_totals.get(m, {}).get(target_col, 0) for m in sorted_months]
                                korean_label = to_korean_label(target_col)
                                result['series'].append({'name': korean_label, 'values': values})
                                print(f'      â”œâ”€ ì‹œë¦¬ì¦ˆ ì¶”ê°€ (ì—‘ì…€ í•©ê³„): {korean_label} = {values[:3]}...', flush=True)
                            result['y_axis_label'] = chart_config.get('y_axis_label', 'ê°’')
                            return result
                        else:
                            # ë‹¨ì¼ ì»¬ëŸ¼
                            values = [monthly_totals.get(m, {}).get(col, 0) for m in sorted_months]
                            print(f'      â””â”€ ì¶”ì¶œëœ ê°’ (ì—‘ì…€ í•©ê³„): {values[:5]}...', flush=True)
                            korean_label = to_korean_label(col)
                            return {
                                'labels': sorted_months,
                                'values': values,
                                'y_axis_label': chart_config.get('y_axis_label', korean_label)
                            }
                
                # ë‹¤ì¤‘ CPO + ë‹¤ì¤‘ ì»¬ëŸ¼ ì¡°í•© ì²˜ë¦¬
                unique_cpos = filtered_df['CPOëª…'].unique().tolist() if 'CPOëª…' in filtered_df.columns else []
                is_multi_cpo = len(unique_cpos) > 1
                is_multi_col = len(columns) > 1
                
                if (is_multi_cpo or is_multi_col) and 'snapshot_month' in filtered_df.columns:
                    print(f'      â”œâ”€ ğŸ”€ ë‹¤ì¤‘ ì‹œë¦¬ì¦ˆ ì°¨íŠ¸ ìƒì„±: CPO={unique_cpos}, ì»¬ëŸ¼={columns}', flush=True)
                    result = {'labels': [], 'series': [], 'multi_series': True}
                    
                    # ë‹¤ì¤‘ CPO + ë‹¤ì¤‘ ì»¬ëŸ¼: CPOë³„ ì»¬ëŸ¼ë³„ ì‹œë¦¬ì¦ˆ ìƒì„±
                    if is_multi_cpo and is_multi_col:
                        for cpo in unique_cpos:
                            cpo_df = filtered_df[filtered_df['CPOëª…'] == cpo]
                            for target_col in columns:
                                if target_col in cpo_df.columns:
                                    grouped = cpo_df.groupby('snapshot_month')[target_col].first().reset_index()
                                    grouped = grouped.sort_values('snapshot_month')
                                    
                                    if not result['labels']:
                                        result['labels'] = grouped['snapshot_month'].tolist()
                                    
                                    series_name = f'{cpo}_{target_col}'
                                    # ì‹œì¥ì ìœ ìœ¨ ë³€í™˜ ì ìš©
                                    values = convert_market_share(target_col, grouped[target_col].tolist())
                                    korean_label = to_korean_label(target_col)
                                    series_name_kr = f'{cpo} {korean_label}'
                                    result['series'].append({
                                        'name': series_name_kr,
                                        'values': values
                                    })
                                    print(f'      â”œâ”€ ì‹œë¦¬ì¦ˆ ì¶”ê°€: {series_name_kr} = {values[:3]}...', flush=True)
                    
                    # ë‹¤ì¤‘ CPO + ë‹¨ì¼ ì»¬ëŸ¼: CPOë³„ ì‹œë¦¬ì¦ˆ ìƒì„±
                    elif is_multi_cpo:
                        target_col = columns[0]
                        korean_label = to_korean_label(target_col)
                        for cpo in unique_cpos:
                            cpo_df = filtered_df[filtered_df['CPOëª…'] == cpo]
                            if target_col in cpo_df.columns:
                                grouped = cpo_df.groupby('snapshot_month')[target_col].first().reset_index()
                                grouped = grouped.sort_values('snapshot_month')
                                
                                if not result['labels']:
                                    result['labels'] = grouped['snapshot_month'].tolist()
                                
                                # ì‹œì¥ì ìœ ìœ¨ ë³€í™˜ ì ìš©
                                values = convert_market_share(target_col, grouped[target_col].tolist())
                                result['series'].append({
                                    'name': f'{cpo} {korean_label}',
                                    'values': values
                                })
                                print(f'      â”œâ”€ ì‹œë¦¬ì¦ˆ ì¶”ê°€: {cpo} {korean_label} = {values[:3]}...', flush=True)
                    
                    # ë‹¨ì¼ CPO + ë‹¤ì¤‘ ì»¬ëŸ¼: ì»¬ëŸ¼ë³„ ì‹œë¦¬ì¦ˆ ìƒì„±
                    else:
                        for target_col in columns:
                            if target_col in filtered_df.columns:
                                if len(unique_cpos) == 1:
                                    grouped = filtered_df.groupby('snapshot_month')[target_col].first().reset_index()
                                else:
                                    grouped = filtered_df.groupby('snapshot_month')[target_col].sum().reset_index()
                                
                                grouped = grouped.sort_values('snapshot_month')
                                
                                if not result['labels']:
                                    result['labels'] = grouped['snapshot_month'].tolist()
                                
                                # ì‹œì¥ì ìœ ìœ¨ ë³€í™˜ ì ìš©
                                values = convert_market_share(target_col, grouped[target_col].tolist())
                                korean_label = to_korean_label(target_col)
                                result['series'].append({
                                    'name': korean_label,
                                    'values': values
                                })
                                print(f'      â”œâ”€ ì‹œë¦¬ì¦ˆ ì¶”ê°€: {korean_label} = {values[:3]}...', flush=True)
                    
                    result['y_axis_label'] = chart_config.get('y_axis_label', 'ê°’')
                    print(f'      â””â”€ âœ… ë‹¤ì¤‘ ì‹œë¦¬ì¦ˆ ë°ì´í„° ì¶”ì¶œ ì™„ë£Œ', flush=True)
                    print(f'         â”œâ”€ ì‹œë¦¬ì¦ˆ ìˆ˜: {len(result["series"])}ê°œ', flush=True)
                    print(f'         â”œâ”€ ë°ì´í„° í¬ì¸íŠ¸: {len(result["labels"])}ê°œ', flush=True)
                    for s in result['series']:
                        print(f'         â”œâ”€ {s["name"]}: {s["values"][:3]}...', flush=True)
                    return result
                
                # ë‹¨ì¼ ì»¬ëŸ¼ì¸ ê²½ìš°
                target_col = col
                if 'snapshot_month' in filtered_df.columns and target_col in filtered_df.columns:
                    if cpo_name and 'CPOëª…' in filtered_df.columns and len(filtered_df['CPOëª…'].unique()) == 1:
                        grouped = filtered_df.groupby('snapshot_month')[target_col].first().reset_index()
                    else:
                        grouped = filtered_df.groupby('snapshot_month')[target_col].sum().reset_index()
                    
                    grouped = grouped.sort_values('snapshot_month')
                    # ì‹œì¥ì ìœ ìœ¨ ë³€í™˜ ì ìš©
                    values = convert_market_share(target_col, grouped[target_col].tolist())
                    print(f'      â””â”€ ì¶”ì¶œëœ ê°’: {values[:5]}...', flush=True)
                    korean_label = to_korean_label(target_col)
                    return {
                        'labels': grouped['snapshot_month'].tolist(),
                        'values': values,
                        'y_axis_label': chart_config.get('y_axis_label', korean_label)
                    }
            
            elif analysis_type == 'comparison':
                # ì „ì²´ CPO + íŠ¹ì • CPO ë¹„êµì¸ ê²½ìš° (ì¦ê° ì»¬ëŸ¼)
                # í•œêµ­ì–´ ë° ì˜ì–´ ì»¬ëŸ¼ëª… ëª¨ë‘ ì²´í¬
                change_columns_kr = ['ì™„ì†ì¦ê°', 'ê¸‰ì†ì¦ê°', 'ì´ì¦ê°', 'ì¶©ì „ì†Œì¦ê°']
                change_columns_en = ['change_slow_chargers', 'change_fast_chargers', 'change_total_chargers', 'change_stations']
                is_change_column = any(c in change_columns_kr or c in change_columns_en for c in columns)
                
                if has_total_cpo and (is_change_column or actual_cpo_list):
                    print(f'      â”œâ”€ ğŸ“Š ì „ì²´ CPO + íŠ¹ì • CPO ë¹„êµ (comparison)', flush=True)
                    print(f'      â”œâ”€ ì›ë³¸ ì»¬ëŸ¼: {columns}', flush=True)
                    
                    # ì»¬ëŸ¼ëª… ì •ê·œí™” (ì˜ì–´ â†’ í•œêµ­ì–´)
                    normalized_columns = [normalize_column(c) for c in columns]
                    print(f'      â”œâ”€ ì •ê·œí™”ëœ ì»¬ëŸ¼: {normalized_columns}', flush=True)
                    
                    # ì—‘ì…€ íŒŒì¼ì—ì„œ ì „ì²´ í•©ê³„ ë°ì´í„° ì¶”ì¶œ
                    from data_loader import ChargingDataLoader
                    loader = ChargingDataLoader()
                    
                    monthly_totals = {}
                    files = loader.list_available_files()
                    
                    for file_info in files:
                        s3_key = file_info['key']
                        filename = file_info['filename']
                        _, snapshot_month = loader.parse_snapshot_date_from_filename(filename)
                        
                        if snapshot_month and (not start_month or snapshot_month >= start_month) and (not end_month or snapshot_month <= end_month):
                            summary = loader.extract_summary_data(s3_key)
                            if summary:
                                monthly_totals[snapshot_month] = {
                                    # ì¦ê°ëŸ‰ (change)
                                    'ì™„ì†ì¦ê°': summary.get('change', {}).get('slow_chargers', 0),
                                    'ê¸‰ì†ì¦ê°': summary.get('change', {}).get('fast_chargers', 0),
                                    'ì´ì¦ê°': summary.get('change', {}).get('total_chargers', 0),
                                    'ì¶©ì „ì†Œì¦ê°': summary.get('change', {}).get('stations', 0),
                                    # ì „ì²´ í˜„í™© (total)
                                    'ì™„ì†ì¶©ì „ê¸°': summary.get('total', {}).get('slow_chargers', 0),
                                    'ê¸‰ì†ì¶©ì „ê¸°': summary.get('total', {}).get('fast_chargers', 0),
                                    'ì´ì¶©ì „ê¸°': summary.get('total', {}).get('total_chargers', 0),
                                    'ì¶©ì „ì†Œìˆ˜': summary.get('total', {}).get('stations', 0),
                                }
                    
                    if monthly_totals:
                        sorted_months = sorted(monthly_totals.keys())
                        result = {'labels': sorted_months, 'series': [], 'multi_series': True}
                        
                        # 1. ì „ì²´ CPO ì‹œë¦¬ì¦ˆ ì¶”ê°€ (ì •ê·œí™”ëœ ì»¬ëŸ¼ëª… ì‚¬ìš©)
                        for i, target_col in enumerate(normalized_columns):
                            original_col = columns[i]  # ì›ë³¸ ì»¬ëŸ¼ëª… (í•œêµ­ì–´ ë¼ë²¨ìš©)
                            values = [monthly_totals.get(m, {}).get(target_col, 0) for m in sorted_months]
                            korean_label = to_korean_label(original_col)
                            result['series'].append({'name': f'ì „ì²´ {korean_label}', 'values': values})
                            print(f'      â”œâ”€ ì‹œë¦¬ì¦ˆ ì¶”ê°€ (ì „ì²´ CPO): ì „ì²´ {korean_label} = {values[:3]}...', flush=True)
                        
                        # 2. íŠ¹ì • CPO ì‹œë¦¬ì¦ˆ ì¶”ê°€
                        for cpo in actual_cpo_list:
                            cpo_mask = df['CPOëª…'].apply(
                                lambda x: cpo.lower() in str(x).lower() if pd.notna(x) else False
                            )
                            cpo_df = df[cpo_mask]
                            
                            if 'snapshot_month' in cpo_df.columns:
                                if start_month:
                                    cpo_df = cpo_df[cpo_df['snapshot_month'] >= start_month]
                                if end_month:
                                    cpo_df = cpo_df[cpo_df['snapshot_month'] <= end_month]
                            
                            for i, target_col in enumerate(normalized_columns):
                                original_col = columns[i]
                                if target_col in cpo_df.columns:
                                    grouped = cpo_df.groupby('snapshot_month')[target_col].first().reset_index()
                                    grouped = grouped.sort_values('snapshot_month')
                                    
                                    values = []
                                    for m in sorted_months:
                                        month_val = grouped[grouped['snapshot_month'] == m][target_col].values
                                        values.append(float(month_val[0]) if len(month_val) > 0 else 0)
                                    
                                    korean_label = to_korean_label(original_col)
                                    result['series'].append({'name': f'{cpo} {korean_label}', 'values': values})
                                    print(f'      â”œâ”€ ì‹œë¦¬ì¦ˆ ì¶”ê°€ ({cpo}): {cpo} {korean_label} = {values[:3]}...', flush=True)
                        
                        result['y_axis_label'] = chart_config.get('y_axis_label', 'ê°’')
                        print(f'      â””â”€ ì „ì²´+CPO ë¹„êµ ì™„ë£Œ: {len(result["series"])}ê°œ ì‹œë¦¬ì¦ˆ', flush=True)
                        return result
                
                # ë‹¤ì¤‘ CPO + ë‹¤ì¤‘ ì»¬ëŸ¼ ì‹œê³„ì—´ ë¹„êµì¸ ê²½ìš° (trendì™€ ìœ ì‚¬í•˜ê²Œ ì²˜ë¦¬)
                unique_cpos = filtered_df['CPOëª…'].unique().tolist() if 'CPOëª…' in filtered_df.columns else []
                is_multi_cpo = len(unique_cpos) > 1
                is_multi_col = len(columns) > 1
                
                # ì‹œê³„ì—´ ë¹„êµê°€ í•„ìš”í•œ ê²½ìš° (ë‹¤ì¤‘ CPO ë˜ëŠ” ë‹¤ì¤‘ ì»¬ëŸ¼ + ê¸°ê°„ í•„í„°)
                if (is_multi_cpo or is_multi_col) and 'snapshot_month' in filtered_df.columns and start_month and end_month:
                    print(f'      â”œâ”€ ğŸ”€ ì‹œê³„ì—´ ë¹„êµ ì°¨íŠ¸ ìƒì„±: CPO={unique_cpos}, ì»¬ëŸ¼={columns}', flush=True)
                    result = {'labels': [], 'series': [], 'multi_series': True}
                    
                    # ë‹¤ì¤‘ CPO + ë‹¤ì¤‘ ì»¬ëŸ¼: CPOë³„ ì»¬ëŸ¼ë³„ ì‹œë¦¬ì¦ˆ ìƒì„±
                    if is_multi_cpo and is_multi_col:
                        for cpo in unique_cpos:
                            cpo_df = filtered_df[filtered_df['CPOëª…'] == cpo]
                            for target_col in columns:
                                if target_col in cpo_df.columns:
                                    grouped = cpo_df.groupby('snapshot_month')[target_col].first().reset_index()
                                    grouped = grouped.sort_values('snapshot_month')
                                    
                                    if not result['labels']:
                                        result['labels'] = grouped['snapshot_month'].tolist()
                                    
                                    korean_label = to_korean_label(target_col)
                                    series_name_kr = f'{cpo} {korean_label}'
                                    # ì‹œì¥ì ìœ ìœ¨ ë³€í™˜ ì ìš©
                                    values = convert_market_share(target_col, grouped[target_col].tolist())
                                    result['series'].append({
                                        'name': series_name_kr,
                                        'values': values
                                    })
                                    print(f'      â”œâ”€ ì‹œë¦¬ì¦ˆ ì¶”ê°€: {series_name_kr} = {values[:3]}...', flush=True)
                    
                    # ë‹¤ì¤‘ CPO + ë‹¨ì¼ ì»¬ëŸ¼
                    elif is_multi_cpo:
                        target_col = columns[0]
                        korean_label = to_korean_label(target_col)
                        for cpo in unique_cpos:
                            cpo_df = filtered_df[filtered_df['CPOëª…'] == cpo]
                            if target_col in cpo_df.columns:
                                grouped = cpo_df.groupby('snapshot_month')[target_col].first().reset_index()
                                grouped = grouped.sort_values('snapshot_month')
                                
                                if not result['labels']:
                                    result['labels'] = grouped['snapshot_month'].tolist()
                                
                                # ì‹œì¥ì ìœ ìœ¨ ë³€í™˜ ì ìš©
                                values = convert_market_share(target_col, grouped[target_col].tolist())
                                result['series'].append({
                                    'name': f'{cpo} {korean_label}',
                                    'values': values
                                })
                                print(f'      â”œâ”€ ì‹œë¦¬ì¦ˆ ì¶”ê°€: {cpo} {korean_label} = {values[:3]}...', flush=True)
                    
                    # ë‹¨ì¼ CPO + ë‹¤ì¤‘ ì»¬ëŸ¼
                    else:
                        for target_col in columns:
                            if target_col in filtered_df.columns:
                                grouped = filtered_df.groupby('snapshot_month')[target_col].first().reset_index()
                                grouped = grouped.sort_values('snapshot_month')
                                
                                if not result['labels']:
                                    result['labels'] = grouped['snapshot_month'].tolist()
                                
                                # ì‹œì¥ì ìœ ìœ¨ ë³€í™˜ ì ìš©
                                values = convert_market_share(target_col, grouped[target_col].tolist())
                                korean_label = to_korean_label(target_col)
                                result['series'].append({
                                    'name': korean_label,
                                    'values': values
                                })
                                print(f'      â”œâ”€ ì‹œë¦¬ì¦ˆ ì¶”ê°€: {korean_label} = {values[:3]}...', flush=True)
                    
                    result['y_axis_label'] = chart_config.get('y_axis_label', 'ê°’')
                    print(f'      â””â”€ ì‹œê³„ì—´ ë¹„êµ ì™„ë£Œ: {len(result["series"])}ê°œ ì‹œë¦¬ì¦ˆ', flush=True)
                    return result
                
                # ê¸°ì¡´ comparison ë¡œì§ (ë‹¨ì¼ ì‹œì  ë¹„êµ)
                sort_col = normalize_column(sort_column) if sort_column else col
                # display_columnì´ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° ì²« ë²ˆì§¸ ì»¬ëŸ¼ ì‚¬ìš©
                if isinstance(display_column, list):
                    display_col = normalize_column(display_column[0])
                else:
                    display_col = normalize_column(display_column) if display_column else col
                
                # ê³„ì‚°ì´ í•„ìš”í•œ ê²½ìš° (ì¦ê°€ë¥  ë“±)
                calculation_info = intent.get('calculation_required', {})
                needs_calculation = calculation_info.get('needed', False)
                
                if needs_calculation:
                    calc_type = calculation_info.get('type')
                    base_col = calculation_info.get('base_column')
                    change_col = calculation_info.get('change_column')
                    
                    base_col = normalize_column(base_col) if base_col else None
                    change_col = normalize_column(change_col) if change_col else None
                    
                    if calc_type == 'growth_rate' and base_col and change_col:
                        sort_col = change_col
                        display_col = base_col
                        y_axis_type = 'calculated_rate'
                        calculation_info['base_column'] = base_col
                        calculation_info['change_column'] = change_col
                
                if 'CPOëª…' in filtered_df.columns and sort_col in filtered_df.columns:
                    latest_month = filtered_df['snapshot_month'].max()
                    latest_df = filtered_df[filtered_df['snapshot_month'] == latest_month]
                    
                    # sort_orderê°€ Noneì´ë©´ ê¸°ë³¸ê°’ 'desc' ì‚¬ìš©
                    effective_sort_order = sort_order if sort_order else 'desc'
                    print(f'      â”œâ”€ SQL ì‹¤í–‰: ORDER BY {sort_col} {effective_sort_order.upper()} LIMIT {result_limit}', flush=True)
                    
                    # ì •ë ¬ ì»¬ëŸ¼ ê¸°ì¤€ìœ¼ë¡œ ìƒìœ„/í•˜ìœ„ ì¶”ì¶œ
                    if effective_sort_order == 'asc':
                        top_df = latest_df.nsmallest(result_limit, sort_col)
                    else:
                        top_df = latest_df.nlargest(result_limit, sort_col)
                    
                    # yì¶• íƒ€ì…ì— ë”°ë¥¸ ê°’ ê³„ì‚° (display_column ì‚¬ìš©)
                    value_col = display_col if display_col in top_df.columns else sort_col
                    calc_info_for_values = calculation_info if needs_calculation else None
                    values = self._calculate_y_values(top_df, value_col, y_axis_type, latest_df, calc_info_for_values)
                    
                    print(f'      â””â”€ ê²°ê³¼: {len(top_df)}ê°œ CPO, ê°’ ì»¬ëŸ¼={value_col}, yì¶•íƒ€ì…={y_axis_type}', flush=True)
                    
                    return {
                        'labels': top_df['CPOëª…'].tolist(),
                        'values': values,
                        'y_axis_type': y_axis_type,
                        'y_axis_label': y_axis_label
                    }
            
            elif analysis_type == 'ranking':
                # ìˆœìœ„ (Text-to-SQL: sort_columnìœ¼ë¡œ ì •ë ¬, display_columnìœ¼ë¡œ í‘œì‹œ)
                sort_col = normalize_column(sort_column) if sort_column else col
                display_col = normalize_column(display_column) if display_column else col
                
                # ê³„ì‚°ì´ í•„ìš”í•œ ê²½ìš° (ì¦ê°€ë¥  ë“±)
                calculation_info = intent.get('calculation_required', {})
                needs_calculation = calculation_info.get('needed', False)
                
                if needs_calculation:
                    calc_type = calculation_info.get('type')
                    base_col = calculation_info.get('base_column')
                    change_col = calculation_info.get('change_column')
                    
                    # ì»¬ëŸ¼ ì •ê·œí™”
                    base_col = normalize_column(base_col) if base_col else None
                    change_col = normalize_column(change_col) if change_col else None
                    
                    print(f'      â”œâ”€ ê³„ì‚° í•„ìš”: {calc_type}', flush=True)
                    print(f'      â”œâ”€ ê¸°ì¤€ ì»¬ëŸ¼: {base_col}, ë³€í™” ì»¬ëŸ¼: {change_col}', flush=True)
                    
                    # ì¦ê°€ë¥  ê³„ì‚°ì„ ìœ„í•´ sort_colê³¼ display_col ì¡°ì •
                    if calc_type == 'growth_rate' and base_col and change_col:
                        sort_col = change_col  # ì¦ê°ëŸ‰ ê¸°ì¤€ ì •ë ¬
                        display_col = base_col  # ê¸°ì¤€ ì»¬ëŸ¼ (ê³„ì‚°ì— ì‚¬ìš©)
                        y_axis_type = 'calculated_rate'
                        calculation_info['base_column'] = base_col
                        calculation_info['change_column'] = change_col
                
                if 'CPOëª…' in filtered_df.columns and sort_col in filtered_df.columns:
                    latest_month = filtered_df['snapshot_month'].max()
                    latest_df = filtered_df[filtered_df['snapshot_month'] == latest_month]
                    
                    # sort_orderê°€ Noneì´ë©´ ê¸°ë³¸ê°’ 'desc' ì‚¬ìš©
                    effective_sort_order = sort_order if sort_order else 'desc'
                    print(f'      â”œâ”€ SQL ì‹¤í–‰: ORDER BY {sort_col} {effective_sort_order.upper()} LIMIT {result_limit}', flush=True)
                    
                    # ì •ë ¬ ì»¬ëŸ¼ ê¸°ì¤€ìœ¼ë¡œ ìƒìœ„/í•˜ìœ„ ì¶”ì¶œ
                    if effective_sort_order == 'asc':
                        top_df = latest_df.nsmallest(result_limit, sort_col)
                    else:
                        top_df = latest_df.nlargest(result_limit, sort_col)
                    
                    # yì¶• íƒ€ì…ì— ë”°ë¥¸ ê°’ ê³„ì‚° (display_column ì‚¬ìš©)
                    value_col = display_col if display_col in top_df.columns else sort_col
                    
                    # ê³„ì‚° ì •ë³´ ì „ë‹¬
                    calc_info_for_values = calculation_info if needs_calculation else None
                    values = self._calculate_y_values(top_df, value_col, y_axis_type, latest_df, calc_info_for_values)
                    labels = top_df['CPOëª…'].tolist()
                    
                    # "ê¸°íƒ€" í•­ëª© ì¶”ê°€ (include_others ì˜µì…˜)
                    include_others = data_filter.get('include_others', False)
                    if include_others and y_axis_type == 'percentage':
                        # Top Nì„ ì œì™¸í•œ ë‚˜ë¨¸ì§€ CPOì˜ ì ìœ ìœ¨ í•©ê³„
                        top_cpos = set(labels)
                        others_df = latest_df[~latest_df['CPOëª…'].isin(top_cpos)]
                        if len(others_df) > 0 and value_col in others_df.columns:
                            others_sum = others_df[value_col].sum()
                            # ì†Œìˆ˜ì  í˜•íƒœë©´ í¼ì„¼íŠ¸ë¡œ ë³€í™˜
                            if others_sum < 1:
                                others_sum = others_sum * 100
                            others_sum = round(float(others_sum), 2)
                            # ì‚¬ìš©ìê°€ ì§€ì •í•œ ë¼ë²¨ ì‚¬ìš© (ê¸°ë³¸ê°’: 'ê¸°íƒ€')
                            others_label = data_filter.get('others_label', 'ê¸°íƒ€')
                            labels.append(others_label)
                            values.append(others_sum)
                            print(f'      â”œâ”€ {others_label} í•­ëª© ì¶”ê°€: {len(others_df)}ê°œ CPO, í•©ê³„ {others_sum}%', flush=True)
                    
                    print(f'      â””â”€ ê²°ê³¼: {len(labels)}ê°œ í•­ëª©, ê°’ ì»¬ëŸ¼={value_col}, yì¶•íƒ€ì…={y_axis_type}', flush=True)
                    
                    return {
                        'labels': labels,
                        'values': values,
                        'y_axis_type': y_axis_type,
                        'y_axis_label': y_axis_label
                    }
            
            # ê¸°ë³¸: ì‹œê°„ë³„ ì¶”ì´
            if 'snapshot_month' in filtered_df.columns and col in filtered_df.columns:
                grouped = filtered_df.groupby('snapshot_month')[col].sum().reset_index()
                grouped = grouped.sort_values('snapshot_month')
                return {
                    'labels': grouped['snapshot_month'].tolist(),
                    'values': convert_values_list(grouped[col].tolist())
                }
            
            return {'labels': [], 'values': [], 'error': 'ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨'}
            
        except Exception as e:
            print(f'âŒ ë°ì´í„° ì¶”ì¶œ ì˜¤ë¥˜: {e}')
            return {'labels': [], 'values': [], 'error': str(e)}
    
    def generate_table_answer(self, query: str, df, kb_context: str, intent: dict,
                               table_data: dict, show_table: bool = True) -> tuple:
        """í‘œ ê¸°ë°˜ ë‹µë³€ ìƒì„± (ì‹œê°í™” ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš© ì•ˆí•¨)"""
        import time
        
        labels = table_data.get('labels', [])
        values = table_data.get('values', [])
        series = table_data.get('series', [])
        is_multi_series = table_data.get('multi_series', False)
        y_axis_type = table_data.get('y_axis_type', 'value')
        y_axis_label = table_data.get('y_axis_label', 'ê°’')
        chart_title = intent.get('chart_title', 'ë°ì´í„° ë¶„ì„ ê²°ê³¼')
        
        table_md = ""
        data_summary = ""
        
        # ë‹¤ì¤‘ ì‹œë¦¬ì¦ˆ í‘œ ìƒì„±
        if show_table and is_multi_series and series:
            # í—¤ë” ìƒì„±: ê¸°ê°„ | ì»¬ëŸ¼1 | ì»¬ëŸ¼2 | ...
            col_names = [s['name'] for s in series]
            header = "| ê¸°ê°„ | " + " | ".join(col_names) + " |"
            separator = "|------|" + "|".join(["------"] * len(col_names)) + "|"
            
            table_rows = []
            for i, label in enumerate(labels):
                row_values = [label]
                for s in series:
                    val = s['values'][i] if i < len(s['values']) else 0
                    if y_axis_type in ['percentage', 'calculated_rate']:
                        row_values.append(f"{val:.1f}%")
                    else:
                        row_values.append(f"{val:,}" if isinstance(val, (int, float)) else str(val))
                table_rows.append("| " + " | ".join(row_values) + " |")
            
            table_md = f"""
## {chart_title}

{header}
{separator}
{chr(10).join(table_rows)}
"""
            # ë°ì´í„° ìš”ì•½
            data_summary = f"- ê¸°ê°„: {labels[0]} ~ {labels[-1]}\n- í•­ëª© ìˆ˜: {len(labels)}ê°œ\n- ì»¬ëŸ¼: {', '.join(col_names)}"
        
        # ë‹¨ì¼ ì‹œë¦¬ì¦ˆ í‘œ ìƒì„±
        elif show_table and labels and values:
            if y_axis_type in ['percentage', 'calculated_rate']:
                formatted_values = [f"{v:.1f}%" for v in values]
            else:
                formatted_values = [f"{v:,}" if isinstance(v, (int, float)) else str(v) for v in values]
            
            table_rows = []
            for i, (label, value) in enumerate(zip(labels, formatted_values), 1):
                table_rows.append(f"| {i} | {label} | {value} |")
            
            table_md = f"""
## {chart_title}

| ìˆœìœ„ | í•­ëª© | {y_axis_label} |
|------|------|----------------|
{chr(10).join(table_rows)}
"""
            data_summary = f"- í•­ëª© ìˆ˜: {len(labels)}ê°œ\n- ë°ì´í„°: {list(zip(labels, values))[:5]}..."
        
        # LLM í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = f"""
ë‹¹ì‹ ì€ ì „ê¸°ì°¨ ì¶©ì „ ì¸í”„ë¼ ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

## ì‚¬ìš©ì ì§ˆë¬¸
{query}

## ë¶„ì„ ê²°ê³¼ ë°ì´í„°
{data_summary if data_summary else f"- í•­ëª© ìˆ˜: {len(labels)}ê°œ"}

{f"## í‘œ í˜•ì‹ ê²°ê³¼{table_md}" if show_table and table_md else ""}

## Knowledge Base ì°¸ê³  ìë£Œ
{kb_context[:1500] if kb_context else 'ì—†ìŒ'}

## ë‹µë³€ ì‘ì„± ì§€ì¹¨
1. {"ìœ„ í‘œë¥¼ ì°¸ê³ í•˜ì—¬ " if show_table else ""}ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì„¸ìš”
2. ì£¼ìš” íŠ¹ì§•ì´ë‚˜ ì¸ì‚¬ì´íŠ¸ë¥¼ ì„¤ëª…í•˜ì„¸ìš”
3. ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”
4. ì‹œê°í™”(ì°¨íŠ¸/ê·¸ë˜í”„)ëŠ” ìƒì„±í•˜ì§€ ë§ˆì„¸ìš” - í‘œ í˜•ì‹ìœ¼ë¡œë§Œ ë‹µë³€í•©ë‹ˆë‹¤
{"5. í‘œë¥¼ ê·¸ëŒ€ë¡œ í¬í•¨í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”" if show_table else "5. í‘œ ì—†ì´ í…ìŠ¤íŠ¸ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”"}

í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.
"""
        
        try:
            start_time = time.time()
            
            payload = {
                'anthropic_version': Config.ANTHROPIC_VERSION,
                'max_tokens': 2048,
                'temperature': 0.5,
                'messages': [{'role': 'user', 'content': prompt}]
            }
            
            response = self.bedrock_client.invoke_model(
                modelId=Config.MODEL_ID,
                contentType='application/json',
                accept='application/json',
                body=json.dumps(payload)
            )
            
            response_body = json.loads(response['body'].read())
            result = response_body['content'][0]['text']
            
            elapsed_time = time.time() - start_time
            print(f'âœ… Bedrock ì‘ë‹µ ì™„ë£Œ (â±ï¸ {elapsed_time:.2f}ì´ˆ)', flush=True)
            
            return result, elapsed_time
            
        except Exception as e:
            # ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ í‘œ í˜•ì‹ ë‹µë³€ ë°˜í™˜
            if show_table:
                return f"ë°ì´í„° ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤.\n{table_md}", 0
            else:
                return f"ë°ì´í„° ë¶„ì„ ê²°ê³¼: {list(zip(labels, values))}", 0
    
    def generate_chart(self, intent: dict, chart_data: dict) -> dict:
        """ì°¨íŠ¸ ìƒì„±"""
        try:
            chart_type = intent.get('chart_type', 'line')
            chart_title = intent.get('chart_title', 'ë°ì´í„° ë¶„ì„')
            
            # ì°¨íŠ¸ ì½”ë“œ ìƒì„±
            code = self.chart_generator.generate_chart_code(
                chart_type=chart_type,
                data=chart_data,
                title=chart_title
            )
            
            # ì½”ë“œ ì‹¤í–‰ ë° ì´ë¯¸ì§€ ìƒì„±
            result = self.chart_generator.execute_chart_code(code)
            
            return result
            
        except Exception as e:
            print(f'âŒ ì°¨íŠ¸ ìƒì„± ì˜¤ë¥˜: {e}')
            return {'success': False, 'error': str(e)}
    
    def generate_answer_with_chart(self, query: str, df, kb_context: str, intent: dict, 
                                    chart_data: dict, chart_result: dict) -> tuple:
        """ì°¨íŠ¸ì™€ í•¨ê»˜ ë‹µë³€ ìƒì„±"""
        import time
        
        # ë‹¤ì¤‘ ì‹œë¦¬ì¦ˆ ì—¬ë¶€ í™•ì¸
        is_multi_series = chart_data.get('multi_series', False)
        
        def format_value(val):
            """ê°’ì„ ì•ˆì „í•˜ê²Œ í¬ë§·íŒ… (ìˆ«ìë©´ ì²œë‹¨ìœ„ êµ¬ë¶„, ë¬¸ìì—´ì´ë©´ ê·¸ëŒ€ë¡œ)"""
            if isinstance(val, (int, float)):
                return f"{val:,}"
            return str(val)
        
        if is_multi_series:
            # ë‹¤ì¤‘ ì‹œë¦¬ì¦ˆ ë°ì´í„° ìš”ì•½
            series_info = []
            for s in chart_data.get('series', []):
                values = s.get('values', [])
                if values:
                    # ìˆ«ì ê°’ë§Œ í•„í„°ë§í•˜ì—¬ min/max ê³„ì‚°
                    numeric_values = [v for v in values if isinstance(v, (int, float))]
                    if numeric_values:
                        min_val = min(numeric_values)
                        max_val = max(numeric_values)
                        series_info.append(f"- {s['name']}: ìµœì†Œ {format_value(min_val)}, ìµœëŒ€ {format_value(max_val)}")
                    else:
                        series_info.append(f"- {s['name']}: {len(values)}ê°œ í•­ëª©")
            
            data_summary = f"""
- ì¡°íšŒ ê¸°ê°„: {chart_data.get('labels', ['N/A'])[0]} ~ {chart_data.get('labels', ['N/A'])[-1]}
- ë°ì´í„° í¬ì¸íŠ¸: {len(chart_data.get('labels', []))}ê°œ
- ì‹œë¦¬ì¦ˆ ìˆ˜: {len(chart_data.get('series', []))}ê°œ
{chr(10).join(series_info)}
"""
            # ë‹¤ì¤‘ ì‹œë¦¬ì¦ˆ í…Œì´ë¸” ìƒì„±
            headers = ['ê¸°ê°„'] + [s['name'] for s in chart_data.get('series', [])]
            table_header = '| ' + ' | '.join(headers) + ' |'
            table_sep = '|' + '|'.join(['------'] * len(headers)) + '|'
            
            rows = []
            labels = chart_data.get('labels', [])
            series_list = chart_data.get('series', [])
            for i, label in enumerate(labels):
                row_values = [label] + [format_value(s['values'][i]) if i < len(s['values']) else 'N/A' for s in series_list]
                rows.append('| ' + ' | '.join(row_values) + ' |')
            
            detail_table = f"{table_header}\n{table_sep}\n" + '\n'.join(rows)
        else:
            # ë‹¨ì¼ ì‹œë¦¬ì¦ˆ ë°ì´í„° ìš”ì•½
            values = chart_data.get('values', [0])
            data_summary = f"""
- ì¡°íšŒ ê¸°ê°„: {chart_data.get('labels', ['N/A'])[0]} ~ {chart_data.get('labels', ['N/A'])[-1]}
- ë°ì´í„° í¬ì¸íŠ¸: {len(values)}ê°œ
- ìµœì†Œê°’: {min(values) if values else 0:,}
- ìµœëŒ€ê°’: {max(values) if values else 0:,}
- í‰ê· ê°’: {sum(values) / max(len(values), 1):,.0f}
"""
            detail_table = "| ê¸°ê°„ | ê°’ |\n|------|-----|\n" + '\n'.join([
                f"| {l} | {v:,} |" for l, v in zip(chart_data.get('labels', []), values)
            ])
        
        prompt = f"""
ë‹¹ì‹ ì€ ì „ê¸°ì°¨ ì¶©ì „ ì¸í”„ë¼ ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

## ì‚¬ìš©ì ì§ˆë¬¸
{query}

## ë¶„ì„ ê²°ê³¼
{data_summary}

## ìƒì„¸ ë°ì´í„°
{detail_table}

## Knowledge Base ì°¸ê³  ìë£Œ
{kb_context[:2000] if kb_context else 'ì—†ìŒ'}

## ë‹µë³€ ì‘ì„± ì§€ì¹¨
1. ì°¨íŠ¸ê°€ ìƒì„±ë˜ì—ˆìŒì„ ì–¸ê¸‰í•˜ì„¸ìš”
2. ë°ì´í„°ì˜ ì£¼ìš” íŠ¸ë Œë“œë¥¼ ì„¤ëª…í•˜ì„¸ìš”
3. ëˆˆì— ë„ëŠ” ë³€í™”ë‚˜ íŠ¹ì´ì ì„ ë¶„ì„í•˜ì„¸ìš”
4. ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”

í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.
"""
        
        try:
            start_time = time.time()
            
            payload = {
                'anthropic_version': Config.ANTHROPIC_VERSION,
                'max_tokens': 2048,
                'temperature': 0.5,
                'messages': [{'role': 'user', 'content': prompt}]
            }
            
            response = self.bedrock_client.invoke_model(
                modelId=Config.MODEL_ID,
                contentType='application/json',
                accept='application/json',
                body=json.dumps(payload)
            )
            
            response_body = json.loads(response['body'].read())
            result = response_body['content'][0]['text']
            
            elapsed_time = time.time() - start_time
            print(f'âœ… Bedrock ì‘ë‹µ ì™„ë£Œ (â±ï¸ {elapsed_time:.2f}ì´ˆ)', flush=True)
            
            return result, elapsed_time
            
        except Exception as e:
            return f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}", 0
    
    def _log_separator(self, title: str):
        """ë¡œê·¸ êµ¬ë¶„ì„  ì¶œë ¥"""
        print(f'\n{"="*60}', flush=True)
        print(f'ğŸ¤– {title}', flush=True)
        print(f'{"="*60}', flush=True)
    
    def _log_step(self, step_num: int, title: str, details: dict = None):
        """ë‹¨ê³„ë³„ ë¡œê·¸ ì¶œë ¥"""
        print(f'\nğŸ“Œ Step {step_num}: {title}', flush=True)
        if details:
            for key, value in details.items():
                if isinstance(value, list) and len(value) > 5:
                    print(f'   â””â”€ {key}: {value[:5]}... (ì´ {len(value)}ê°œ)', flush=True)
                elif isinstance(value, str) and len(value) > 200:
                    print(f'   â””â”€ {key}: {value[:200]}... (ì´ {len(value)}ì)', flush=True)
                else:
                    print(f'   â””â”€ {key}: {value}', flush=True)
    
    def process_query(self, query: str, df, full_df) -> dict:
        """ì „ì²´ ì§ˆì˜ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸"""
        import time
        total_start_time = time.time()  # ì „ì²´ ì²˜ë¦¬ ì‹œê°„ ì¸¡ì • ì‹œì‘
        
        self._log_separator(f'Agent ì§ˆì˜ ì²˜ë¦¬ ì‹œì‘')
        print(f'ğŸ“ ì‚¬ìš©ì ì§ˆì˜: "{query}"', flush=True)
        
        # ========================================
        # Step 1: ë©”ëª¨ë¦¬ ë°ì´í„° ìˆ˜ì§‘
        # ========================================
        available_data = {
            'available_months': sorted(full_df['snapshot_month'].unique().tolist()) if 'snapshot_month' in full_df.columns else [],
            'available_cpos': full_df['CPOëª…'].unique().tolist() if 'CPOëª…' in full_df.columns else [],
            'available_columns': list(full_df.columns)
        }
        
        self._log_step(1, 'ë©”ëª¨ë¦¬ ë°ì´í„° ìˆ˜ì§‘ (S3 ìºì‹œ)', {
            'ì „ì²´ ë°ì´í„° í–‰ ìˆ˜': len(full_df),
            'í˜„ì¬ í•„í„° ë°ì´í„° í–‰ ìˆ˜': len(df) if df is not None else 0,
            'ì‚¬ìš© ê°€ëŠ¥í•œ ì›”': available_data['available_months'],
            'ì‚¬ìš© ê°€ëŠ¥í•œ CPO ìˆ˜': len(available_data['available_cpos']),
            'ì»¬ëŸ¼ ëª©ë¡': available_data['available_columns']
        })
        
        # ========================================
        # Step 2: RAG - Knowledge Base ê²€ìƒ‰
        # ========================================
        self._log_step(2, 'RAG - Knowledge Base ê²€ìƒ‰', {
            'Knowledge Base ID': Config.KNOWLEDGE_BASE_ID,
            'ê²€ìƒ‰ ì¿¼ë¦¬': query,
            'ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ ì„¤ì •': Config.KB_NUMBER_OF_RESULTS
        })
        
        kb_context = self.retrieve_from_kb(query)
        
        print(f'   â””â”€ KB ê²€ìƒ‰ ê²°ê³¼: {len(kb_context)} ì ì»¨í…ìŠ¤íŠ¸ íšë“', flush=True)
        if kb_context:
            # KB ê²°ê³¼ ìš”ì•½ ì¶œë ¥
            kb_preview = kb_context[:300].replace('\n', ' ')
            print(f'   â””â”€ KB ì»¨í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°: {kb_preview}...', flush=True)
        
        # ========================================
        # Step 3: í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ - ì§ˆì˜ ì˜ë„ ë¶„ì„
        # ========================================
        self._log_step(3, 'í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ - ì§ˆì˜ ì˜ë„ ë¶„ì„', {
            'LLM ëª¨ë¸': Config.MODEL_ID,
            'ë¶„ì„ ëª©ì ': 'ì°¨íŠ¸ í•„ìš” ì—¬ë¶€, ì°¨íŠ¸ íƒ€ì…, ë°ì´í„° í•„í„° ì¡°ê±´ íŒë‹¨'
        })
        
        intent = self.analyze_query_intent(query, available_data)
        
        # Multi-Step Reasoning ë¶„ì„ ê²°ê³¼ ì¶œë ¥
        reasoning = intent.get('reasoning', {})
        if reasoning:
            print(f'   â””â”€ ğŸ§  Multi-Step Reasoning ë¶„ì„:', flush=True)
            
            step1 = reasoning.get('step1_extraction', {})
            print(f'      â”œâ”€ Step1 (ìš”ì†Œ ì¶”ì¶œ):', flush=True)
            print(f'         â”œâ”€ ëŒ€ìƒ: {step1.get("target", "N/A")}', flush=True)
            print(f'         â”œâ”€ ì¸¡ì •ê°’: {step1.get("metric", "N/A")}', flush=True)
            print(f'         â””â”€ ì¡°ê±´: {step1.get("conditions", "N/A")}', flush=True)
            
            step2 = reasoning.get('step2_column_mapping', {})
            print(f'      â”œâ”€ Step2 (ì»¬ëŸ¼ ë§¤í•‘):', flush=True)
            print(f'         â”œâ”€ ì‚¬ìš©ì í‘œí˜„: {step2.get("user_expression", "N/A")}', flush=True)
            print(f'         â”œâ”€ ë§¤í•‘ ì»¬ëŸ¼: {step2.get("mapped_column", "N/A")}', flush=True)
            print(f'         â””â”€ ë§¤í•‘ ì´ìœ : {step2.get("mapping_reason", "N/A")}', flush=True)
            
            step3 = reasoning.get('step3_confidence', {})
            print(f'      â”œâ”€ Step3 (í™•ì‹ ë„): {step3.get("level", "N/A")} - {step3.get("reason", "N/A")}', flush=True)
            
            step4 = reasoning.get('step4_decision', {})
            print(f'      â””â”€ Step4 (ê²°ì •): {step4.get("action", "N/A")} - {step4.get("explanation", "N/A")}', flush=True)
        
        # ê³„ì‚° í•„ìš” ì—¬ë¶€ ì¶œë ¥
        calc_required = intent.get('calculation_required', {})
        if calc_required.get('needed'):
            print(f'   â””â”€ ğŸ“ ê³„ì‚° í•„ìš”:', flush=True)
            print(f'      â”œâ”€ íƒ€ì…: {calc_required.get("type", "N/A")}', flush=True)
            print(f'      â”œâ”€ ê¸°ì¤€ ì»¬ëŸ¼: {calc_required.get("base_column", "N/A")}', flush=True)
            print(f'      â””â”€ ë³€í™” ì»¬ëŸ¼: {calc_required.get("change_column", "N/A")}', flush=True)
        
        print(f'   â””â”€ ğŸ“Š ìµœì¢… ë¶„ì„ ê²°ê³¼:', flush=True)
        print(f'      â”œâ”€ ì¶œë ¥ í˜•ì‹: {intent.get("output_format", "table")}', flush=True)
        print(f'      â”œâ”€ ì°¨íŠ¸ í•„ìš”: {intent.get("needs_chart")}', flush=True)
        print(f'      â”œâ”€ í‘œ í‘œì‹œ: {intent.get("show_table", True)}', flush=True)
        print(f'      â”œâ”€ ì°¨íŠ¸ íƒ€ì…: {intent.get("chart_type", "none")}', flush=True)
        print(f'      â”œâ”€ ì œëª©: {intent.get("chart_title")}', flush=True)
        print(f'      â”œâ”€ ë¶„ì„ ìœ í˜•: {intent.get("analysis_type")}', flush=True)
        print(f'      â”œâ”€ ë°ì´í„° í•„í„°: {intent.get("data_filter")}', flush=True)
        chart_config = intent.get('chart_config', {})
        if chart_config:
            print(f'      â””â”€ ì„¤ì •: xì¶•={chart_config.get("x_axis")}, yì¶•={chart_config.get("y_axis")}, yì¶•íƒ€ì…={chart_config.get("y_axis_type")}, yì¶•ë¼ë²¨={chart_config.get("y_axis_label")}', flush=True)
        else:
            print(f'      â””â”€ ì„¤ì •: ê¸°ë³¸ê°’ ì‚¬ìš©', flush=True)
        
        # ========================================
        # Step 3.5: ëª…í™•í™” í•„ìš” ì—¬ë¶€ í™•ì¸
        # ========================================
        if intent.get('needs_clarification'):
            clarification_msg = intent.get('clarification_message', 'ì§ˆì˜ë¥¼ ë” êµ¬ì²´ì ìœ¼ë¡œ í•´ì£¼ì„¸ìš”.')
            reasoning = intent.get('reasoning', {})
            confidence = reasoning.get('step3_confidence', {})
            
            print(f'   â””â”€ âš ï¸ ëª…í™•í™” í•„ìš”: {confidence.get("level", "UNKNOWN")}', flush=True)
            print(f'   â””â”€ ì´ìœ : {confidence.get("reason", "N/A")}', flush=True)
            print(f'   â””â”€ ë©”ì‹œì§€: {clarification_msg}', flush=True)
            
            total_time = time.time() - total_start_time
            self._log_separator('Agent ì²˜ë¦¬ ì™„ë£Œ (ëª…í™•í™” ìš”ì²­)')
            
            return {
                'success': True,
                'query': query,
                'answer': clarification_msg,
                'has_chart': False,
                'needs_clarification': True,
                'bedrock_time': 0,
                'total_time': round(total_time, 2)
            }
        
        # ========================================
        # Step 4: ë„êµ¬ ì„ íƒ ë° ì‹¤í–‰
        # ========================================
        if intent.get('needs_chart'):
            self._log_step(4, 'ë„êµ¬ ì„ íƒ: ì½”ë“œ ì¸í„°í”„ë¦¬í„° (ì°¨íŠ¸ ìƒì„±)', {
                'ì„ íƒëœ ë„êµ¬': 'ChartGenerator (matplotlib ê¸°ë°˜)',
                'ì°¨íŠ¸ íƒ€ì…': intent.get('chart_type'),
                'ì‹¤í–‰ ë°©ì‹': 'Python ì½”ë“œ ë™ì  ìƒì„± â†’ subprocess ì‹¤í–‰ â†’ Base64 ì´ë¯¸ì§€ ë°˜í™˜'
            })
            
            # ì°¨íŠ¸ ë°ì´í„° ì¶”ì¶œ
            print(f'\n   ğŸ“Š ë°ì´í„° ì¶”ì¶œ ì¤‘...', flush=True)
            chart_data = self.extract_chart_data(full_df, intent)
            
            if chart_data.get('error'):
                total_time = time.time() - total_start_time
                print(f'   â””â”€ âŒ ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨: {chart_data["error"]}', flush=True)
                return {
                    'success': False,
                    'error': chart_data['error'],
                    'has_chart': False,
                    'bedrock_time': 0,
                    'total_time': round(total_time, 2)
                }
            
            # ë°ì´í„° ì¶”ì¶œ ê²°ê³¼ ë¡œê¹…
            is_multi = chart_data.get('multi_series', False)
            if is_multi:
                series_count = len(chart_data.get('series', []))
                data_points = len(chart_data.get('labels', []))
                print(f'   â””â”€ âœ… ë‹¤ì¤‘ ì‹œë¦¬ì¦ˆ ë°ì´í„° ì¶”ì¶œ ì™„ë£Œ', flush=True)
                print(f'      â”œâ”€ ì‹œë¦¬ì¦ˆ ìˆ˜: {series_count}ê°œ', flush=True)
                print(f'      â”œâ”€ ë°ì´í„° í¬ì¸íŠ¸: {data_points}ê°œ', flush=True)
                for s in chart_data.get('series', []):
                    print(f'      â”œâ”€ {s["name"]}: {s["values"][:3]}...', flush=True)
            else:
                data_points = len(chart_data.get('values', []))
                print(f'   â””â”€ âœ… ë‹¨ì¼ ì‹œë¦¬ì¦ˆ ë°ì´í„° ì¶”ì¶œ ì™„ë£Œ', flush=True)
                print(f'      â”œâ”€ ë°ì´í„° í¬ì¸íŠ¸: {data_points}ê°œ', flush=True)
                print(f'      â”œâ”€ ë¼ë²¨: {chart_data.get("labels", [])[:5]}...', flush=True)
                print(f'      â””â”€ ê°’: {chart_data.get("values", [])[:5]}...', flush=True)
            
            # ========================================
            # Step 5: ì½”ë“œ ì¸í„°í”„ë¦¬í„° ì‹¤í–‰ (ì°¨íŠ¸ ìƒì„±)
            # ========================================
            self._log_step(5, 'ì½”ë“œ ì¸í„°í”„ë¦¬í„° ì‹¤í–‰ - ì°¨íŠ¸ ìƒì„±', {
                'ì‹¤í–‰ ë°©ì‹': 'matplotlib Python ì½”ë“œ ìƒì„± â†’ subprocess ì‹¤í–‰',
                'ì¶œë ¥ í˜•ì‹': 'Base64 ì¸ì½”ë”© PNG ì´ë¯¸ì§€'
            })
            
            chart_result = self.generate_chart(intent, chart_data)
            
            if not chart_result.get('success'):
                print(f'   â””â”€ âš ï¸ ì°¨íŠ¸ ìƒì„± ì‹¤íŒ¨: {chart_result.get("error")}', flush=True)
                chart_result = {'success': False, 'image': None}
            else:
                img_size = len(chart_result.get('image', '')) if chart_result.get('image') else 0
                print(f'   â””â”€ âœ… ì°¨íŠ¸ ìƒì„± ì„±ê³µ (ì´ë¯¸ì§€ í¬ê¸°: {img_size:,} bytes)', flush=True)
            
            # ========================================
            # Step 6: LLM ë‹µë³€ ìƒì„±
            # ========================================
            self._log_step(6, 'LLM ë‹µë³€ ìƒì„±', {
                'LLM ëª¨ë¸': Config.MODEL_ID,
                'ì…ë ¥ ë°ì´í„°': f'ì°¨íŠ¸ ë°ì´í„° + KB ì»¨í…ìŠ¤íŠ¸ ({len(kb_context)}ì)',
                'ë‹µë³€ ìœ í˜•': 'ì°¨íŠ¸ ë¶„ì„ + ì¸ì‚¬ì´íŠ¸'
            })
            
            answer, bedrock_time = self.generate_answer_with_chart(
                query, df, kb_context, intent, chart_data, chart_result
            )
            
            print(f'   â””â”€ âœ… ë‹µë³€ ìƒì„± ì™„ë£Œ ({len(answer)}ì)', flush=True)
            
            # ========================================
            # ì²˜ë¦¬ ì™„ë£Œ ìš”ì•½
            # ========================================
            total_time = time.time() - total_start_time
            self._log_separator('Agent ì²˜ë¦¬ ì™„ë£Œ')
            print(f'ğŸ“Š ì²˜ë¦¬ ìš”ì•½:', flush=True)
            print(f'   â”œâ”€ ì§ˆì˜: {query[:50]}...', flush=True)
            print(f'   â”œâ”€ ì°¨íŠ¸ ìƒì„±: {"ì„±ê³µ" if chart_result.get("success") else "ì‹¤íŒ¨"}', flush=True)
            print(f'   â”œâ”€ ì°¨íŠ¸ íƒ€ì…: {intent.get("chart_type")}', flush=True)
            print(f'   â”œâ”€ ë°ì´í„° ì†ŒìŠ¤: S3 ìºì‹œ (ë©”ëª¨ë¦¬)', flush=True)
            print(f'   â”œâ”€ RAG ì‚¬ìš©: {"ì˜ˆ" if kb_context else "ì•„ë‹ˆì˜¤"} ({len(kb_context)}ì)', flush=True)
            print(f'   â”œâ”€ Bedrock ì‘ë‹µ ì‹œê°„: {bedrock_time:.2f}ì´ˆ', flush=True)
            print(f'   â”œâ”€ ì „ì²´ ì²˜ë¦¬ ì‹œê°„: {total_time:.2f}ì´ˆ', flush=True)
            print(f'   â””â”€ ë‹µë³€ ê¸¸ì´: {len(answer)}ì', flush=True)
            
            return {
                'success': True,
                'query': query,
                'answer': answer,
                'has_chart': chart_result.get('success', False),
                'chart_image': chart_result.get('image'),
                'chart_type': intent.get('chart_type'),
                'chart_title': intent.get('chart_title'),
                'bedrock_time': round(bedrock_time, 2),
                'total_time': round(total_time, 2),
                'data_summary': {
                    'labels': chart_data.get('labels', []),
                    'values': chart_data.get('values', []),
                    'series': chart_data.get('series', []),
                    'count': data_points
                }
            }
        
        else:
            # ========================================
            # Step 4: í‘œ ê¸°ë°˜ ë‹µë³€ ìƒì„± (ì°¨íŠ¸ ë¶ˆí•„ìš”)
            # ========================================
            output_format = intent.get('output_format', 'table')
            show_table = intent.get('show_table', True)
            
            self._log_step(4, 'ë„êµ¬ ì„ íƒ: í‘œ ê¸°ë°˜ ë‹µë³€', {
                'ì¶œë ¥ í˜•ì‹': output_format,
                'í‘œ í‘œì‹œ': show_table,
                'ì´ìœ ': 'ì‹œê°í™” í‚¤ì›Œë“œ ì—†ìŒ - í‘œ í˜•ì‹ìœ¼ë¡œ ë‹µë³€'
            })
            
            # ë°ì´í„° ì¶”ì¶œ (ì°¨íŠ¸ì™€ ë™ì¼í•œ ë¡œì§ ì‚¬ìš©)
            print(f'\n   ğŸ“Š í‘œ ë°ì´í„° ì¶”ì¶œ ì¤‘...', flush=True)
            table_data = self.extract_chart_data(full_df, intent)
            
            if table_data.get('error'):
                total_time = time.time() - total_start_time
                print(f'   â””â”€ âŒ ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨: {table_data["error"]}', flush=True)
                return {
                    'success': False,
                    'error': table_data['error'],
                    'has_chart': False,
                    'bedrock_time': 0,
                    'total_time': round(total_time, 2)
                }
            
            # ë‹¤ì¤‘ ì‹œë¦¬ì¦ˆ ì—¬ë¶€ í™•ì¸
            is_multi = table_data.get('multi_series', False)
            if is_multi:
                series_count = len(table_data.get('series', []))
                data_points = len(table_data.get('labels', []))
                print(f'   â””â”€ âœ… ë‹¤ì¤‘ ì‹œë¦¬ì¦ˆ í‘œ ë°ì´í„° ì¶”ì¶œ ì™„ë£Œ', flush=True)
                print(f'      â”œâ”€ ì‹œë¦¬ì¦ˆ ìˆ˜: {series_count}ê°œ', flush=True)
                print(f'      â”œâ”€ ë°ì´í„° í¬ì¸íŠ¸: {data_points}ê°œ', flush=True)
                for s in table_data.get('series', []):
                    print(f'      â”œâ”€ {s["name"]}: {s["values"][:3]}...', flush=True)
            else:
                data_points = len(table_data.get('values', []))
                print(f'   â””â”€ âœ… í‘œ ë°ì´í„° ì¶”ì¶œ ì™„ë£Œ ({data_points}ê°œ í•­ëª©)', flush=True)
            
            # ========================================
            # Step 5: í‘œ ê¸°ë°˜ LLM ë‹µë³€ ìƒì„±
            # ========================================
            self._log_step(5, 'LLM ë‹µë³€ ìƒì„± (í‘œ í˜•ì‹)', {
                'LLM ëª¨ë¸': Config.MODEL_ID,
                'ì¶œë ¥ í˜•ì‹': output_format,
                'í‘œ í‘œì‹œ': show_table
            })
            
            answer, bedrock_time = self.generate_table_answer(
                query, df, kb_context, intent, table_data, show_table
            )
            
            print(f'   â””â”€ âœ… ë‹µë³€ ìƒì„± ì™„ë£Œ ({len(answer)}ì)', flush=True)
            
            # ========================================
            # ì²˜ë¦¬ ì™„ë£Œ ìš”ì•½
            # ========================================
            total_time = time.time() - total_start_time
            self._log_separator('Agent ì²˜ë¦¬ ì™„ë£Œ (í‘œ ëª¨ë“œ)')
            print(f'ğŸ“Š ì²˜ë¦¬ ìš”ì•½:', flush=True)
            print(f'   â”œâ”€ ì§ˆì˜: {query[:50]}...', flush=True)
            print(f'   â”œâ”€ ì¶œë ¥ í˜•ì‹: {output_format}', flush=True)
            print(f'   â”œâ”€ í‘œ í‘œì‹œ: {show_table}', flush=True)
            print(f'   â”œâ”€ ë°ì´í„° ì†ŒìŠ¤: S3 ìºì‹œ (ë©”ëª¨ë¦¬)', flush=True)
            print(f'   â”œâ”€ RAG ì‚¬ìš©: {"ì˜ˆ" if kb_context else "ì•„ë‹ˆì˜¤"} ({len(kb_context)}ì)', flush=True)
            print(f'   â”œâ”€ Bedrock ì‘ë‹µ ì‹œê°„: {bedrock_time:.2f}ì´ˆ', flush=True)
            print(f'   â”œâ”€ ì „ì²´ ì²˜ë¦¬ ì‹œê°„: {total_time:.2f}ì´ˆ', flush=True)
            print(f'   â””â”€ ë‹µë³€ ê¸¸ì´: {len(answer)}ì', flush=True)
            
            return {
                'success': True,
                'query': query,
                'answer': answer,
                'has_chart': False,
                'show_table': show_table,
                'bedrock_time': round(bedrock_time, 2),
                'total_time': round(total_time, 2),
                'output_format': output_format,
                'data_summary': {
                    'labels': table_data.get('labels', []),
                    'values': table_data.get('values', []),
                    'count': data_points
                }
            }
